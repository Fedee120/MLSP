{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA = \"llama2-70b-4096\"\n",
    "GEMMA = \"gemma-7b-it\"\n",
    "MIXTRAL = \"mixtral-8x7b-32768\"\n",
    "\n",
    "oracion = \"El susurro del viento me transportó a un estado de serenidad profunda que no había experimentado antes.\"\n",
    "palabra = \"profunda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidatos\": [\"encantada\", \"fascinante\", \"sobrenatural\", \"misterioso\", \"maravilloso\"]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidatos': ['encantada',\n",
       "  'fascinante',\n",
       "  'sobrenatural',\n",
       "  'misterioso',\n",
       "  'maravilloso',\n",
       "  'profunda']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "def get_groq_simplifications(model: str, oracion: str, palabra: str):\n",
    "    client = Groq(\n",
    "        api_key=\"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\",\n",
    "    )\n",
    "\n",
    "    oracion_ejemplo = \"El resplandeciente sol iluminaba el paisaje selvático, creando un efecto casi mágico en la vegetación exuberante que se extendía a lo lejos.\"\n",
    "    palabra_ejemplo = \"mágico\"\n",
    "\n",
    "    params = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "                    Tarea: Sustituir una palabra en una oración sin cambiar el orden de las demás palabras.\n",
    "                    Respuesta: La respuesta solo incluye los candidatos. Tu respuesta no debe incluir todas las oraciones, solo las palabras por las que se quiere sustituir. La respuesta debe ser en el siguiente formato JSON:\n",
    "                        {{\n",
    "                            \"candidatos\": [\"candidato1\", \"candidato2\", \"candidato3\", \"candidato4\", \"candidato5\"],\n",
    "                        }}\n",
    "\n",
    "                    Ejemplo de oración original: \"{oracion_ejemplo}\" Palabra a sustituir: \"{palabra_ejemplo}\" Respuesta: {{ \"candidatos\": [ \"encantador\", \"fascinante\", \"sobrenatural\", \"misterioso\", \"maravilloso\"] }}\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                    La oración original es: \"{oracion}\" La palabra a sustituir es \"{palabra}\".\n",
    "                    Instrucciones: Proporciona cinco candidatos para sustituir la palabra \"{palabra}\" en la oración, manteniendo el significado general y la coherencia de la oración. Los candidatos no deben alterar el orden de las demás palabras en la oración.\n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": f\"{model}\",  # Aquí debes reemplazar \"model\" por el identificador de modelo real que deseas utilizar.\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "    }\n",
    "\n",
    "\n",
    "    if model != LLAMA: params[\"response_format\"] = { \"type\": \"json_object\" }\n",
    "\n",
    "    chat_completion = client.chat.completions.create(**params)\n",
    "\n",
    "    output = json.loads(chat_completion.choices[0].message.content)\n",
    "    output['candidatos'].append(palabra)\n",
    "\n",
    "    return output\n",
    "\n",
    "get_groq_simplifications(GEMMA, oracion, palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/CREA_total.TXT', sep='\\t', header=None,\n",
    "                 names=['Orden', 'Palabra', 'Frec.absoluta', 'Frec.normalizada'],\n",
    "                 encoding='ISO 8859-1', low_memory=False,\n",
    "                 dtype={'Orden': str, 'Palabra': str, 'Frec.absoluta': str, 'Frec.normalizada': float})\n",
    "\n",
    "\n",
    "# Asegurarse de que 'Frec.normalizada' se interprete como numérico\n",
    "df['Frec.normalizada'] = pd.to_numeric(df['Frec.normalizada'], errors='coerce')\n",
    "\n",
    "# Ordenar el DataFrame por 'Frec.normalizada' para un mejor gráfico\n",
    "df_sorted = df.sort_values(by='Frec.normalizada', ascending=True)\n",
    "\n",
    "# Suponiendo que ya has cargado los datos en el DataFrame df\n",
    "# Convertir explícitamente la columna 'Palabra' a cadenas de texto\n",
    "df['Palabra'] = df['Palabra'].astype(str)\n",
    "\n",
    "# Ordenar el DataFrame por 'Frec.normalizada' para un mejor gráfico\n",
    "df_sorted = df.sort_values(by='Frec.normalizada', ascending=True)\n",
    "\n",
    "# Convertir 'Frec.normalizada' a numérico, por si acaso no lo está\n",
    "df['Frec.normalizada'] = pd.to_numeric(df['Frec.normalizada'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frec.absoluta</th>\n",
       "      <th>Frec.normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orden</td>\n",
       "      <td>Frec.absoluta</td>\n",
       "      <td>Frec.normalizada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>de</td>\n",
       "      <td>9,999,518</td>\n",
       "      <td>65545.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>la</td>\n",
       "      <td>6,277,560</td>\n",
       "      <td>41148.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>que</td>\n",
       "      <td>4,681,839</td>\n",
       "      <td>30688.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>el</td>\n",
       "      <td>4,569,652</td>\n",
       "      <td>29953.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Orden         Palabra       Frec.absoluta  Frec.normalizada\n",
       "0       Orden  Frec.absoluta    Frec.normalizada                NaN\n",
       "1          1.              de          9,999,518           65545.55\n",
       "2          2.              la          6,277,560           41148.59\n",
       "3          3.            que           4,681,839           30688.85\n",
       "4          4.              el          4,569,652           29953.48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "# Función para remover acentos y caracteres diacríticos\n",
    "def remover_acentos(input_str):\n",
    "    if isinstance(input_str, float):  # Verifica si el valor es un float (lo que usualmente indica un NaN en pandas)\n",
    "        return \"\"  # Devuelve una cadena vacía si el valor es NaN\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return \"\".join(c for c in nfkd_form if not unicodedata.combining(c))\n",
    "\n",
    "def obtener_frecuencias_de_sustitutos(candidatos):\n",
    "    # Leer el DataFrame asegurándose de que las columnas tienen el tipo correcto\n",
    "    # Es posible que necesites ajustar los tipos dependiendo de los datos\n",
    "    df = pd.read_csv('data/CREA_total.TXT', sep='\\t', header=None,\n",
    "                    names=['Orden', 'Palabra', 'Frec.absoluta', 'Frec.normalizada'],\n",
    "                    encoding='ISO 8859-1', low_memory=False,\n",
    "                    dtype={'Orden': str, 'Palabra': str, 'Frec.absoluta': str, 'Frec.normalizada': float})\n",
    "\n",
    "    # Crear una nueva lista con las palabras sin acentos y en minúsculas\n",
    "    candidatos_minuscula = [remover_acentos(palabra).lower() for palabra in candidatos[\"candidatos\"]]\n",
    "\n",
    "    # Normalizar la columna 'Palabra' en el DataFrame para que coincida con la lista de candidatos\n",
    "    df['Palabra'] = df['Palabra'].astype(str).apply(remover_acentos).str.lower().str.strip()\n",
    "\n",
    "    # Filtrar el DataFrame para obtener solo las filas que contienen las palabras candidatas\n",
    "    df_filtrado = df[df['Palabra'].isin(candidatos_minuscula)]\n",
    "\n",
    "    df_unicas_filtradas = df_filtrado.drop_duplicates(subset='Palabra')\n",
    "\n",
    "    return df_unicas_filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_predicciones(oracion_p: str, palabra_p: str):\n",
    "    candidatos_mixtral = get_groq_simplifications(MIXTRAL, oracion_p, palabra_p)\n",
    "    df_filtrado_mixtral = obtener_frecuencias_de_sustitutos(candidatos_mixtral)\n",
    "\n",
    "    candidatos_llama = get_groq_simplifications(LLAMA, oracion_p, palabra_p)\n",
    "    df_filtrado_llama = obtener_frecuencias_de_sustitutos(candidatos_llama)\n",
    "\n",
    "    candidatos_gemma = get_groq_simplifications(GEMMA, oracion_p, palabra_p)\n",
    "    df_filtrado_gemma = obtener_frecuencias_de_sustitutos(candidatos_gemma)\n",
    "\n",
    "    # combinamos filtrados de los modelos\n",
    "    df_merged = pd.concat([df_filtrado_mixtral, df_filtrado_llama, df_filtrado_gemma], ignore_index=True)\n",
    "\n",
    "    # Ordenamos segun frecuencia absoluta\n",
    "    df_merged = df_merged.sort_values('Frec.absoluta', ascending=False)\n",
    "\n",
    "    # Elimino duplicados\n",
    "    df_merged = df_merged.drop_duplicates(subset='Palabra')\n",
    "\n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linea 1/30\n",
      "Linea 2/30\n",
      "Linea 3/30\n",
      "Linea 4/30\n",
      "Linea 5/30\n",
      "Linea 6/30\n",
      "Linea 7/30\n",
      "Linea 8/30\n",
      "Linea 9/30\n",
      "Linea 10/30\n",
      "Linea 11/30\n",
      "Linea 12/30\n",
      "Linea 13/30\n",
      "Linea 14/30\n",
      "Linea 15/30\n",
      "Linea 16/30\n",
      "Linea 17/30\n",
      "Linea 18/30\n",
      "Linea 19/30\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 11 column 1 (char 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m target_words\u001b[38;5;241m.\u001b[39mappend(target_word)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Obtener prediccion\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m predicciones \u001b[38;5;241m=\u001b[39m \u001b[43mobtener_predicciones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predicciones[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPalabra\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Guardar oracion, palabra y predicciones en la lista\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mobtener_predicciones\u001b[0;34m(oracion_p, palabra_p)\u001b[0m\n\u001b[1;32m      2\u001b[0m candidatos_mixtral \u001b[38;5;241m=\u001b[39m get_groq_simplifications(MIXTRAL, oracion_p, palabra_p)\n\u001b[1;32m      3\u001b[0m df_filtrado_mixtral \u001b[38;5;241m=\u001b[39m obtener_frecuencias_de_sustitutos(candidatos_mixtral)\n\u001b[0;32m----> 5\u001b[0m candidatos_llama \u001b[38;5;241m=\u001b[39m \u001b[43mget_groq_simplifications\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLLAMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moracion_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalabra_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_filtrado_llama \u001b[38;5;241m=\u001b[39m obtener_frecuencias_de_sustitutos(candidatos_llama)\n\u001b[1;32m      8\u001b[0m candidatos_gemma \u001b[38;5;241m=\u001b[39m get_groq_simplifications(GEMMA, oracion_p, palabra_p)\n",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m, in \u001b[0;36mget_groq_simplifications\u001b[0;34m(model, oracion, palabra)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m LLAMA: params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m }\n\u001b[1;32m     42\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 44\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidatos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(palabra)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 11 column 1 (char 79)"
     ]
    }
   ],
   "source": [
    "# Trial data\n",
    "\n",
    "spanish_input_file = \"/home/spoturno/coding/MLSP_Data/Data/Trial/Spanish/multilex_trial_es_ls.tsv\" # change this\n",
    "output_file = '/home/spoturno/coding/MLSP/metrics/groq-models-with-crea-corpus/predictions_trial.tsv'\n",
    "\n",
    "sentences = []\n",
    "target_words = []\n",
    "\n",
    "cant_ejemplos = 30\n",
    "i = 1\n",
    "\n",
    "with open(spanish_input_file, 'r', encoding='utf-8') as file, open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "    for line in file:\n",
    "        # Separamos la linea en tabulaciones \n",
    "        parts = line.strip().split('\\t')\n",
    "        sentence = parts[0]\n",
    "        target_word = parts[1]\n",
    "\n",
    "        # Guardo la oracion y palabra ordenadamente\n",
    "        sentences.append(sentence)\n",
    "        target_words.append(target_word)\n",
    "\n",
    "        # Obtener prediccion\n",
    "        predicciones = obtener_predicciones(sentence, target_word)\n",
    "        predictions = predicciones['Palabra'].to_list()\n",
    "\n",
    "        try:\n",
    "            # Obtener prediccion\n",
    "            predicciones = obtener_predicciones(sentence, target_word)\n",
    "            predictions = predicciones['Palabra'].to_list()\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando linea {i}: {e}\")\n",
    "            continue  # Skipear linea y avanzar si ocurrio error\n",
    "\n",
    "        # Preparar la linea a escribir en el archivo de salida\n",
    "        output_line = f\"{sentence}\\t{target_word}\\t\" + '\\t'.join(predictions) + '\\n'\n",
    "        out_file.write(output_line)\n",
    "\n",
    "        print(f\"Linea {i}/{cant_ejemplos} \\u2713\")\n",
    "        i += 1\n",
    "\n",
    "    if i == 30: print(\"Completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linea 19/30 ✓\n",
      "Error processing line 20: Extra data: line 11 column 1 (char 79)\n",
      "Error processing line 21: Extra data: line 11 column 1 (char 78)\n",
      "Linea 22/30 ✓\n",
      "Linea 23/30 ✓\n",
      "Linea 24/30 ✓\n",
      "Linea 25/30 ✓\n",
      "Linea 26/30 ✓\n",
      "Linea 27/30 ✓\n",
      "Linea 28/30 ✓\n",
      "Linea 29/30 ✓\n",
      "Linea 30/30 ✓\n",
      "Completado!\n"
     ]
    }
   ],
   "source": [
    "# NO EJECUTAR SI NO OCURRIO ERROR\n",
    "# Continuacion de script previo por si ocurrio error \n",
    "\n",
    "spanish_input_file = \"/home/spoturno/coding/MLSP_Data/Data/Trial/Spanish/multilex_trial_es_ls.tsv\" # change this\n",
    "output_file = '/home/spoturno/coding/MLSP/metrics/groq-models-with-crea-corpus/predictions_trial.tsv'\n",
    "\n",
    "sentences = []\n",
    "target_words = []\n",
    "\n",
    "cant_ejemplos = 30\n",
    "i = 0\n",
    "\n",
    "with open(spanish_input_file, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Skipear a linea 19\n",
    "        i += 1\n",
    "        if i < 19: continue \n",
    "\n",
    "        # Separamos la linea en tabulaciones \n",
    "        parts = line.strip().split('\\t')\n",
    "        sentence = parts[0]\n",
    "        target_word = parts[1]\n",
    "\n",
    "        # Guardo la oracion y palabra ordenadamente\n",
    "        sentences.append(sentence)\n",
    "        target_words.append(target_word)\n",
    "\n",
    "        try:\n",
    "            # Obtener prediccion\n",
    "            predicciones = obtener_predicciones(sentence, target_word)\n",
    "            predictions = predicciones['Palabra'].to_list()\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando linea {i}: {e}\")\n",
    "            continue  # Skipear linea y avanzar si ocurrio error\n",
    "\n",
    "        # Preparar la linea a escribir en el archivo de salida\n",
    "        output_line = f\"{sentence}\\t{target_word}\\t\" + '\\t'.join(predictions) + '\\n'\n",
    "\n",
    "        with open(output_file, 'a', encoding='utf-8') as out_file:\n",
    "            out_file.write(output_line)\n",
    "\n",
    "        print(f\"Linea {i}/{cant_ejemplos} \\u2713\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    if i == 30: print(\"Completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidatos\": [\"forma\", \"tipo\", \"método\", \"mecanismo\", \"marcha\"]\n",
      "}\n",
      "{\n",
      "  \"candidatos\": [\"encantador\", \"fascinante\", \"sobrenatural\", \"misterioso\", \"maravilloso\"]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orden</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frec.absoluta</th>\n",
       "      <th>Frec.normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.</td>\n",
       "      <td>forma</td>\n",
       "      <td>97,165</td>\n",
       "      <td>636.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197.</td>\n",
       "      <td>tipo</td>\n",
       "      <td>56,606</td>\n",
       "      <td>371.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730.</td>\n",
       "      <td>marcha</td>\n",
       "      <td>18,427</td>\n",
       "      <td>120.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1479.</td>\n",
       "      <td>metodo</td>\n",
       "      <td>9,626</td>\n",
       "      <td>63.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433.</td>\n",
       "      <td>mecanismo</td>\n",
       "      <td>5,960</td>\n",
       "      <td>39.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4908.</td>\n",
       "      <td>modalidad</td>\n",
       "      <td>2,810</td>\n",
       "      <td>18.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6047.</td>\n",
       "      <td>maravilloso</td>\n",
       "      <td>2,214</td>\n",
       "      <td>14.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7411.</td>\n",
       "      <td>misterioso</td>\n",
       "      <td>1,730</td>\n",
       "      <td>11.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9546.</td>\n",
       "      <td>fascinante</td>\n",
       "      <td>1,253</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13852.</td>\n",
       "      <td>sobrenatural</td>\n",
       "      <td>769</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18416.</td>\n",
       "      <td>encantador</td>\n",
       "      <td>519</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Orden       Palabra Frec.absoluta  Frec.normalizada\n",
       "0      107.         forma        97,165            636.90\n",
       "1      197.          tipo        56,606            371.04\n",
       "2      730.        marcha        18,427            120.78\n",
       "3     1479.        metodo         9,626             63.09\n",
       "4     2433.     mecanismo         5,960             39.06\n",
       "5     4908.     modalidad         2,810             18.41\n",
       "7     6047.   maravilloso         2,214             14.51\n",
       "8     7411.    misterioso         1,730             11.33\n",
       "9     9546.    fascinante         1,253              8.21\n",
       "10   13852.  sobrenatural           769              5.04\n",
       "11   18416.    encantador           519              3.40"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete this if necesary, LLAMA2 is works badly with JSON response output\n",
    "\n",
    "def obtener_predicciones_v2(oracion_p: str, palabra_p: str):\n",
    "    candidatos_mixtral = get_groq_simplifications(MIXTRAL, oracion_p, palabra_p)\n",
    "    df_filtrado_mixtral = obtener_frecuencias_de_sustitutos(candidatos_mixtral)\n",
    "\n",
    "    candidatos_gemma = get_groq_simplifications(GEMMA, oracion_p, palabra_p)\n",
    "    df_filtrado_gemma = obtener_frecuencias_de_sustitutos(candidatos_gemma)\n",
    "\n",
    "    # combinamos filtrados de los modelos\n",
    "    df_merged = pd.concat([df_filtrado_mixtral, df_filtrado_gemma], ignore_index=True)\n",
    "\n",
    "    # Ordenamos segun frecuencia absoluta\n",
    "    df_merged = df_merged.sort_values('Frec.absoluta', ascending=False)\n",
    "\n",
    "    # Elimino duplicados\n",
    "    df_merged = df_merged.drop_duplicates(subset='Palabra')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "# Los siguientes resultados fueron agregados manualmente al .tsv \n",
    "obtener_predicciones_v2(\"Los seguros son una modalidad de gestión financiera que le ayudará a las personas a prevenir descalabros en sus ingresos y en su seguridad personal que en un momento dado son inevitables y que a cualquier persona pueden ocurrirle.\", \"modalidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
