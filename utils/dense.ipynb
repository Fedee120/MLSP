{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\loque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "# Supongamos que tus datos están en un archivo JSON llamado 'converted_data.jsonl'\n",
    "with open('../scripts/converted_data.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convertir los datos en un DataFrame de pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behold, there came up out of the river seven c...</td>\n",
       "      <td>river</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a fellow bondservant with you and with yo...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The man, the lord of the land, said to us, 'By...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shimei had sixteen sons and six daughters; but...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"He has put my brothers far from me.</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence     token  complexity\n",
       "0  Behold, there came up out of the river seven c...     river    0.000000\n",
       "1  I am a fellow bondservant with you and with yo...  brothers    0.000000\n",
       "2  The man, the lord of the land, said to us, 'By...  brothers    0.050000\n",
       "3  Shimei had sixteen sons and six daughters; but...  brothers    0.150000\n",
       "4               \"He has put my brothers far from me.  brothers    0.263889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar posibles filas con valores faltantes\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Tokenización y limpieza de las oraciones\n",
    "stop_words = set(stopwords.words('spanish') + list(string.punctuation))\n",
    "\n",
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['oracion_procesada'] = df['sentence'].apply(preprocess)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['oracion_procesada', 'token']], df['complexity'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Crear representaciones TF-IDF para las oraciones\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['oracion_procesada']).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['oracion_procesada']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1226/1226 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.0027 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0162 - accuracy: 0.0027 - val_loss: 0.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.0027 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0129 - accuracy: 0.0027 - val_loss: 0.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0112 - accuracy: 0.0027 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0094 - accuracy: 0.0027 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0082 - accuracy: 0.0027 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0077 - accuracy: 0.0027 - val_loss: 0.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0070 - accuracy: 0.0027 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1226/1226 [==============================] - 2s 2ms/step - loss: 0.0067 - accuracy: 0.0027 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2508c96fee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_tfidf.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Salida entre 0 y 1 para complejidad\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_tfidf, y_train, epochs=10, batch_size=4, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_tfidf, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
