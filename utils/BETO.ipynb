{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoturno/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/spoturno/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la oración: tensor([[ 6.3808e-01, -2.7869e-01, -1.9846e-01, -1.4776e-01,  3.0291e-01,\n",
      "          7.8052e-01,  9.3867e-02,  7.2238e-01, -4.6559e-02,  4.8533e-01,\n",
      "          1.1943e-01, -1.0878e+00,  3.5126e-01, -3.5981e-01,  4.9066e-01,\n",
      "         -7.4640e-01, -4.0938e-01, -1.9730e-01, -3.7721e-02,  1.0112e-01,\n",
      "          1.4318e-01,  5.2502e-02,  6.6922e-02, -1.2755e-01, -1.3663e-01,\n",
      "          5.8162e-03,  3.3418e-01, -8.0998e-02, -4.7620e-01, -8.3185e-02,\n",
      "          1.0710e-01,  1.7079e-01, -2.2541e-01,  4.2820e-01,  5.9104e-01,\n",
      "         -4.4022e-01,  1.2989e-02, -3.1058e-01, -3.8460e-01, -6.4842e-01,\n",
      "          1.3952e-01,  8.7414e-01,  7.6276e-01,  6.0126e-01, -3.9091e-02,\n",
      "          1.7234e-01, -1.6539e-01,  1.2365e-01,  1.5036e-01, -5.5027e-01,\n",
      "          3.2842e-01, -2.8708e-02, -3.6269e-01, -2.3796e-01,  6.1217e-01,\n",
      "         -1.7270e-02,  2.6563e-01,  1.4247e-01, -4.9820e-01,  5.1619e-01,\n",
      "          7.6938e-01,  2.9431e-01,  5.6767e-02, -3.4350e-01,  2.2901e-01,\n",
      "          5.4656e-02,  2.3299e-02,  1.1706e+00, -2.2197e-01, -4.5741e-02,\n",
      "          1.9164e-01, -6.7925e-01,  4.0971e-01, -1.4069e-01,  2.4823e-01,\n",
      "          4.2665e-01,  7.0757e-01,  6.5202e-01,  1.2250e-01, -4.8227e-01,\n",
      "         -3.6032e-01,  7.2380e-02,  3.7368e-01, -2.5553e-01,  3.8803e-01,\n",
      "         -5.3839e-01,  4.8072e-01, -1.2139e-01, -1.4491e-01,  1.6893e-01,\n",
      "          1.5740e-01,  2.1156e-01,  1.3272e-01, -1.4226e-01,  5.5756e-03,\n",
      "          1.7899e-01,  5.3654e-01, -1.0321e+00,  5.1885e-02,  7.3231e-01,\n",
      "         -6.2169e-01,  7.5915e-01, -2.2501e-01,  1.4842e-01,  5.8922e-01,\n",
      "         -1.2889e+00,  1.3390e+00, -4.0064e+00,  1.4241e-02,  1.8090e-01,\n",
      "          1.9464e-01,  2.2039e-01, -7.0445e-02,  6.1950e-01, -2.0448e-02,\n",
      "         -5.6913e-01,  2.9925e-01, -2.1818e-01,  7.2549e-02, -2.4494e-01,\n",
      "         -1.1951e-01,  8.0834e-01,  4.2676e-01, -2.1732e-01,  2.9969e-01,\n",
      "          8.9773e-01, -8.6717e-01,  3.8994e-01, -1.2665e-01, -1.6692e-01,\n",
      "         -1.0599e-01, -5.6337e-02, -8.2591e-02,  7.6812e-02,  3.4336e-01,\n",
      "         -4.5404e-02, -7.6241e-01, -2.5912e-01, -2.7373e-01,  3.4736e-01,\n",
      "         -3.4753e-01, -1.7161e-01,  2.5836e-01, -1.1668e-01, -1.4595e-01,\n",
      "         -2.2175e-01, -1.5376e-01,  5.5391e-01,  9.3630e-01, -4.8452e-01,\n",
      "          2.1175e-01, -1.4682e-01,  4.7808e-01, -5.0656e-01, -1.2057e+00,\n",
      "         -5.5471e-01, -5.0302e-01,  9.5998e-03,  2.7015e-01, -3.9098e-01,\n",
      "         -3.2245e-01, -1.0414e+00,  9.1437e-02,  2.1166e-01,  9.2383e-01,\n",
      "         -2.1255e-01,  6.6813e-01, -3.1040e-01,  1.2391e-01,  2.2823e-01,\n",
      "         -2.3198e-02, -4.8228e-01, -2.2351e-02,  3.3493e-01,  7.6900e-02,\n",
      "          4.1524e-01, -9.3357e-01,  2.2505e-02,  2.2392e-01, -2.2260e-01,\n",
      "          5.6802e-02, -1.3709e-01,  7.0215e-01, -4.5397e-01, -8.8421e-01,\n",
      "          3.2224e-02,  1.5049e-01, -2.6566e-01,  4.1688e-01, -7.2681e-01,\n",
      "          6.9483e-01, -2.9294e-01,  6.2604e-01, -3.3036e-02, -7.1221e-01,\n",
      "         -4.6875e-01, -3.3098e-01,  3.9842e-01, -3.8021e-01, -1.5473e-01,\n",
      "          3.2529e-02,  9.7418e-02,  4.4325e-01,  5.4479e-01,  6.6691e-01,\n",
      "         -1.0978e+00, -1.0781e+00,  4.9045e-01, -4.8354e-01,  6.6540e-01,\n",
      "         -7.8275e+00,  8.6781e-03, -7.6373e-01,  2.7524e-01, -5.0699e-01,\n",
      "         -5.7288e-01,  3.8672e-02,  2.9521e-01, -4.9385e-01,  2.9906e-01,\n",
      "          8.2501e-01,  6.1131e-01,  7.1050e-02, -7.0987e-01,  3.9823e-02,\n",
      "         -4.9925e-01,  3.0317e-01, -1.2757e-01,  2.5798e-01,  6.5335e-01,\n",
      "          5.1779e-01, -7.5545e-01, -4.9763e-01,  1.6297e-01, -5.5971e-01,\n",
      "         -3.7077e-01, -4.4493e-01, -4.6171e-01, -8.2208e-01,  2.2162e-01,\n",
      "         -2.9789e-01,  3.2664e-01, -3.9860e-02, -8.6086e-02,  7.1386e-02,\n",
      "         -2.0408e-01,  3.4398e-01, -5.2662e-02,  1.1456e+00,  5.6476e-01,\n",
      "          1.6035e-01, -1.6578e-01,  1.5078e-01,  1.9845e-01, -8.2630e-01,\n",
      "         -1.2672e-01, -6.2279e-01,  4.2180e-02, -2.0963e-01,  8.7844e-02,\n",
      "         -6.5942e-01, -1.4892e-02,  1.4663e-01, -3.6777e-01, -6.4045e-01,\n",
      "         -4.1120e-01,  1.3506e-01, -9.4383e-01,  4.0475e-02,  1.4832e-01,\n",
      "          5.2396e-01,  8.5694e-02, -4.0860e-01, -2.8137e-01,  4.6750e-01,\n",
      "          6.6220e-01, -5.6247e-01,  1.5153e-01, -1.2745e+00, -1.5793e-01,\n",
      "          6.3491e-01, -1.9560e-01, -7.2376e-02, -3.6094e-01,  1.1569e+00,\n",
      "          6.6760e-02,  1.5512e-01, -6.6474e-01,  8.1394e-01, -2.9771e-01,\n",
      "          2.8309e-01,  7.1780e-01, -3.2355e-01,  3.6398e-02,  4.9835e-01,\n",
      "         -2.9194e-01, -3.5746e-01, -3.7116e-01, -2.4371e-01,  7.4604e-02,\n",
      "          4.2429e-01,  2.1011e-01,  7.8312e-01,  1.0137e+00, -1.0154e-01,\n",
      "         -1.3172e+00, -4.9552e-01, -1.7311e-01,  7.6277e-01, -1.1519e-01,\n",
      "          2.9938e-03,  1.3672e+00, -5.7322e-01, -2.8622e-01, -9.3774e-01,\n",
      "          2.3243e-01,  9.0775e-01, -2.4358e-01,  2.0115e-02,  7.9544e-01,\n",
      "         -3.6549e-01,  5.0045e-01, -4.3227e-01, -8.5439e-02, -1.6560e-01,\n",
      "          5.6072e-01,  9.0131e-03, -7.4546e-03, -6.3031e-02, -4.1155e-01,\n",
      "         -3.9937e-01, -4.0248e-01, -3.8819e-01,  4.1991e-01, -8.7178e-01,\n",
      "          1.8228e-01,  3.2383e-01,  1.5685e-01, -5.8409e-02,  1.1671e-01,\n",
      "         -7.1548e-01, -2.4745e-01, -9.2137e-01, -3.8144e-01, -1.0827e-01,\n",
      "          8.1273e-01,  2.4611e-01, -2.4674e-01, -3.4113e-01, -7.7706e-02,\n",
      "         -3.0468e-01,  7.1060e-01, -2.7726e-01, -1.3786e-02,  2.2712e-01,\n",
      "         -4.0661e-01,  9.1332e-01, -1.3161e-01, -4.1692e-01,  1.4584e-01,\n",
      "         -4.5732e-01, -1.5027e-01, -2.4169e-01,  4.7510e-01,  8.3916e-01,\n",
      "          9.2846e-02,  2.1201e-01, -5.4225e-01, -2.3003e-01,  3.3851e-01,\n",
      "          2.3205e-01, -1.9417e-01, -6.2825e-01,  1.0929e+00,  3.5012e-01,\n",
      "         -9.4771e-01, -2.7600e-01,  1.4746e-01, -5.1019e-01, -4.2050e-01,\n",
      "          7.1478e-01,  1.1583e-01, -2.8069e-01,  9.2157e-01,  6.6598e-01,\n",
      "          2.5757e-01,  7.2573e-01,  1.9109e-02, -8.1637e-02,  5.4996e-02,\n",
      "         -8.1388e-01,  5.9317e-02, -5.1855e-01,  2.4748e-01,  6.2133e-01,\n",
      "         -4.7652e-01,  5.7810e-01, -7.0429e-01,  2.1585e-01,  4.1991e-03,\n",
      "         -6.0368e-02, -2.6762e-01, -2.8412e-01,  9.9581e-01, -4.1445e-01,\n",
      "          1.7067e-01,  5.3563e-01, -8.8334e-01, -3.7551e-02,  3.7808e-01,\n",
      "         -3.0806e-01, -4.3462e-01, -2.4872e-01, -7.9498e-01, -3.5213e-01,\n",
      "         -6.6024e-01,  1.9848e+00, -1.0408e-01,  8.1906e-01,  5.3999e-01,\n",
      "          7.8591e-02, -2.1554e-01, -3.1655e-01, -2.8681e-01,  3.7454e-02,\n",
      "          1.0827e+00,  6.6591e-02, -3.7314e-01,  7.9348e-01, -3.2858e-01,\n",
      "          1.7873e-03, -2.0592e-01, -3.8491e-01, -3.3109e-01,  4.0256e-01,\n",
      "         -2.1940e-01, -8.5931e-02, -5.7942e-03, -1.6313e-02,  1.3511e+00,\n",
      "          1.2449e-01,  3.5120e-01, -3.3516e-01, -2.7821e-01,  4.6984e-01,\n",
      "          1.0429e+00, -9.6334e-02,  2.4260e-01,  6.6188e-01, -6.3377e-01,\n",
      "         -5.1635e-01, -3.1616e-01,  1.7234e-01,  4.1077e-01,  1.0183e+00,\n",
      "         -1.0201e+00, -3.5696e-01, -5.8011e-01,  7.7932e-02, -2.7776e-01,\n",
      "         -7.1787e-01, -2.1158e-02, -4.4824e-01, -1.8083e+00,  1.5637e-01,\n",
      "         -3.4993e-01, -9.8394e-01, -1.5196e+00, -6.4687e-01,  1.9200e-01,\n",
      "         -2.4309e-01, -4.9047e-01, -1.3052e-01,  4.1982e-01,  3.1081e-01,\n",
      "         -2.2139e-01,  1.6260e-01,  1.0822e+00, -4.8573e-01, -3.3474e-01,\n",
      "         -5.4293e-01,  9.8519e-02, -4.4120e-02, -6.8845e-02,  5.0290e-01,\n",
      "         -1.1181e+00,  7.4030e-01,  3.4272e-01,  1.3267e-01,  9.2568e-01,\n",
      "         -5.9526e-01,  1.7963e-01,  1.9069e-01,  6.8897e-01, -2.4926e-01,\n",
      "         -9.2334e-02,  3.6767e-01, -8.9961e-01, -1.2001e-01,  1.0166e+00,\n",
      "          2.9566e-01, -1.2209e-01,  4.6631e-01, -5.8352e-01, -1.5718e-01,\n",
      "         -4.8561e-01, -4.9386e-01, -5.5439e-01,  3.1279e-01, -2.8687e-01,\n",
      "         -1.9980e-01,  1.2368e-01,  1.0087e+00,  5.6568e-01,  3.5183e-01,\n",
      "         -3.4965e-01, -3.9853e-01,  1.1129e-01,  4.8556e-01, -1.1497e-01,\n",
      "          3.6731e-01,  5.0054e-01,  1.3235e-01, -5.9355e-02,  4.6088e-01,\n",
      "         -5.9733e-01,  2.1210e-01,  1.8985e-01, -9.0318e-03, -3.7408e-01,\n",
      "          2.6082e-01,  1.8206e-01,  2.3124e-01, -1.2320e+00, -1.6051e-01,\n",
      "          5.9191e-02,  1.0951e+00, -5.1247e-01, -2.0456e-01, -5.2713e-01,\n",
      "          5.1566e-01, -9.1212e-01,  4.5276e-01, -7.2890e-02, -1.8373e-01,\n",
      "          2.6283e-01, -1.1056e-01,  2.6262e-02, -2.2802e-01, -8.4689e-01,\n",
      "         -6.3462e-01, -2.0660e-01,  3.1066e-01,  7.5166e-03, -3.0515e-01,\n",
      "         -1.7981e-01, -4.3573e-01,  1.1606e-01, -1.1255e+01, -6.9296e-01,\n",
      "          6.6084e-01, -1.1098e-01, -5.8800e-02,  4.1058e-02,  3.2083e-01,\n",
      "          1.8596e-01, -3.7057e-01, -5.0690e-01, -2.6233e-01,  2.9524e-01,\n",
      "          1.1924e+00, -5.3948e-01, -5.4173e-01, -4.0594e-01, -2.6519e-01,\n",
      "          2.7425e-01,  2.3026e-01, -8.4117e-02, -2.8083e-01, -5.6902e-02,\n",
      "         -6.3213e-01,  1.7367e-01,  4.2734e-01, -8.3956e-01,  3.2899e-01,\n",
      "         -1.1279e-01, -2.1048e-01,  8.8454e-01,  4.6722e-01, -4.7233e-01,\n",
      "         -4.3432e-03, -3.9956e-01,  8.3105e-01, -3.9797e-01, -1.0637e-01,\n",
      "          1.4452e-01,  1.6028e-01,  1.0159e-01, -6.0111e-01, -3.2069e-01,\n",
      "         -2.8888e-01,  1.5896e-01,  1.8503e-01,  4.8713e-01,  2.5445e-01,\n",
      "         -1.1287e-01, -4.6544e-02,  1.2215e+00,  9.8503e-01,  2.5347e-01,\n",
      "          1.0768e+00, -5.7689e-01,  1.9835e-01,  3.7738e-01,  4.4718e-01,\n",
      "          7.5543e-02, -5.8555e-02, -4.5640e-01, -4.8773e-01,  1.7591e-01,\n",
      "          2.2826e-01, -7.0500e-02, -1.1873e-01,  3.8637e-01, -2.4280e-02,\n",
      "         -3.0368e-01,  6.1115e-01, -1.3077e-01, -4.7276e-01, -9.3133e-01,\n",
      "         -2.0584e-01, -2.0808e-01, -1.4765e-01, -4.2222e-01, -9.4475e-01,\n",
      "         -7.0276e-01, -3.6335e-01,  4.0612e-01,  4.2297e-01, -4.7510e-01,\n",
      "         -3.3037e-02, -3.0712e-01,  6.9213e-02, -4.0996e-01, -1.1216e-01,\n",
      "         -8.0143e-01, -7.5459e-02, -1.7295e-02,  1.7895e-01,  7.7409e-02,\n",
      "         -5.3205e-01,  4.1488e-02,  6.7716e-01, -5.0974e-01,  4.8603e-01,\n",
      "          8.1466e-01,  5.8619e-01,  4.5293e-01,  6.2994e-01, -2.9320e-01,\n",
      "          1.1029e+00,  3.4106e-01,  3.2443e-01, -3.2732e-01, -2.7557e-01,\n",
      "          7.8236e-01, -6.1562e-01,  2.4784e-01,  4.3942e-01,  3.2014e-01,\n",
      "          8.4462e-01, -4.0970e-01,  3.3205e-02, -2.2592e-01, -6.1388e-02,\n",
      "          4.9428e-01,  3.5807e-01,  1.0452e+00, -2.5209e-02,  6.0836e-01,\n",
      "         -7.0606e-01,  6.1137e-01,  2.3412e-01, -6.2845e-01,  2.5340e-02,\n",
      "         -7.5225e-02,  2.1656e-01,  3.7654e-01, -4.3343e-01, -3.9244e-01,\n",
      "         -1.8053e-01,  7.8931e-01, -3.3529e-01, -4.8532e-01,  1.3169e-02,\n",
      "          2.9534e-02,  1.4241e-01,  2.8444e-02, -4.4112e-01, -9.3713e-01,\n",
      "          2.1299e-01, -1.6348e-01, -1.8427e-01, -6.5661e-02, -3.1764e-01,\n",
      "         -5.3278e-01,  2.2274e-01,  1.9805e-01,  2.2089e-01, -9.0776e-01,\n",
      "          2.8805e-01,  1.2338e+00,  1.0899e+00,  6.4805e-01,  7.0943e-01,\n",
      "          6.7203e-02,  1.0514e+00, -9.6491e-01, -5.2045e-01, -1.5405e-01,\n",
      "         -5.8397e-01,  2.1185e-01, -1.4337e+00, -4.6307e-01, -8.5101e-01,\n",
      "         -5.6044e-01,  4.9831e-01,  2.6793e-01, -9.0340e-01,  1.4603e-01,\n",
      "         -9.0344e-02, -5.6050e-01,  1.6341e-01, -2.1756e-02,  6.9088e-01,\n",
      "          8.3390e-01,  2.0623e-02, -4.1925e-01,  4.2609e-01, -1.6042e-01,\n",
      "          4.5718e-01,  1.0983e-01,  2.3367e-01,  2.1064e-01,  8.4254e-01,\n",
      "         -3.8998e-02, -7.5355e-02, -2.2032e-01,  1.3734e-01,  7.0637e-01,\n",
      "          9.7983e-02,  2.1374e-01,  5.2576e-02, -1.0675e+00, -2.3992e-01,\n",
      "         -2.5484e-01,  9.7701e-01, -6.2863e-01,  4.4528e-01, -1.0535e+00,\n",
      "         -2.7687e-01, -3.5165e-01, -3.8038e-01,  2.5838e-02,  9.0959e-01,\n",
      "          2.1218e-01,  1.3388e-01,  1.4071e-01]])\n",
      "Embeddings de las palabras: tensor([[[ 0.6381, -0.2787, -0.1985,  ...,  0.2122,  0.1339,  0.1407],\n",
      "         [ 0.4672, -0.3835, -0.2334,  ..., -0.1781, -0.5380,  0.2391],\n",
      "         [-0.1892,  0.3194, -0.3417,  ...,  0.0925, -0.7950,  0.0272],\n",
      "         ...,\n",
      "         [ 0.4276,  0.0904, -0.0048,  ...,  0.3439,  0.1649,  0.4735],\n",
      "         [-0.0356,  0.3053, -0.0507,  ...,  0.1680,  0.1654, -0.1134],\n",
      "         [-0.5077, -0.3374, -0.7238,  ..., -0.1003, -0.3568,  0.2244]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Carga el tokenizador y el modelo BETO\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model_beto = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "# Oración de ejemplo\n",
    "sentence = \"Hola, esto es una prueba con BERT.\"\n",
    "\n",
    "# Tokeniza la oración\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Obtiene los embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model_beto(**inputs)\n",
    "\n",
    "# Los embeddings de la última capa oculta serían\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Embedding del [CLS] token que representa la oración entera\n",
    "sentence_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "# Embeddings de cada token/palabra en la oración\n",
    "word_embeddings = last_hidden_states\n",
    "\n",
    "print(\"Embedding de la oración:\", sentence_embedding)\n",
    "print(\"Embeddings de las palabras:\", word_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/data_mlsp_fing.csv', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>palabraCompleja</th>\n",
       "      <th>evaluacion_normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             oracion palabraCompleja  \\\n",
       "0                trabajo abnegado de los sanitarios         abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...   paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...      incidencia   \n",
       "3  Es la primera vez que me toca participar en un...     autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...            seno   \n",
       "\n",
       "   evaluacion_normalizada  \n",
       "0                     3.0  \n",
       "1                     4.0  \n",
       "2                     1.5  \n",
       "3                     3.0  \n",
       "4                     2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         3.0  \n",
       "1         4.0  \n",
       "2         1.5  \n",
       "3         3.0  \n",
       "4         2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.rename(columns={'oracion': 'sentence', 'palabraCompleja': 'target_word', 'evaluacion_normalizada': 'complexity'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizemos la columna de complexity dividiendo entre 5 todo\n",
    "df['complexity'] = df['complexity']/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         0.6  \n",
       "1         0.8  \n",
       "2         0.3  \n",
       "3         0.6  \n",
       "4         0.4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check for cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_beto.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1859/1859 [01:26<00:00, 21.53it/s]\n",
      "Processing: 100%|██████████| 1859/1859 [00:51<00:00, 36.30it/s]\n",
      "Processing: 100%|██████████| 465/465 [00:23<00:00, 19.96it/s]\n",
      "Processing: 100%|██████████| 465/465 [00:13<00:00, 35.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que df es tu DataFrame que incluye las columnas 'sentence', 'target_word' y 'complexity'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embeddings(text_list, tokenizer, model, device):\n",
    "    \"\"\"Obtiene embeddings [CLS] para una lista de textos, con barra de progreso.\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=\"Processing\", leave=True):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu())\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "\n",
    "def process_dataframe(df, tokenizer, model, device):\n",
    "    \"\"\"Procesa un dataframe para obtener embeddings y complejidades.\"\"\"\n",
    "    sentence_embeddings = get_embeddings(df['sentence'].tolist(), tokenizer, model, device)\n",
    "    word_embeddings = get_embeddings(df['target_word'].tolist(), tokenizer, model, device)\n",
    "    complexities = torch.tensor(df['complexity'].values, dtype=torch.float).unsqueeze(1)\n",
    "    return torch.cat((sentence_embeddings, word_embeddings, complexities), dim=1)\n",
    "\n",
    "# Procesar los conjuntos de entrenamiento y prueba\n",
    "train_data = process_dataframe(train_df, tokenizer, model_beto, device)\n",
    "test_data = process_dataframe(test_df, tokenizer, model_beto, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1859, 1537]), torch.Size([465, 1537]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de entrenamiento (todas las columnas excepto la última)\n",
    "train_features = train_data[:, :-1]\n",
    "# Objetivos de entrenamiento (última columna)\n",
    "train_targets = train_data[:, -1]\n",
    "\n",
    "# Entradas de prueba\n",
    "test_features = test_data[:, :-1]\n",
    "# Objetivos de prueba\n",
    "test_targets = test_data[:, -1]\n",
    "\n",
    "# Asegúrate de que los tensores estén en la CPU para convertirlos a arrays de NumPy\n",
    "train_features_np = train_features.numpy()\n",
    "train_targets_np = train_targets.numpy()\n",
    "test_features_np = test_features.numpy()\n",
    "test_targets_np = test_targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:03:15.602467: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-23 13:03:15.602739: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-23 13:03:15.605045: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-23 13:03:15.628952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 13:03:16.153654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoturno/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m393,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=rmse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5495 - mean_absolute_error: 0.4684 - val_loss: 0.2439 - val_mean_absolute_error: 0.1991\n",
      "Epoch 2/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2405 - mean_absolute_error: 0.1953 - val_loss: 0.2679 - val_mean_absolute_error: 0.2012\n",
      "Epoch 3/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2184 - mean_absolute_error: 0.1713 - val_loss: 0.2494 - val_mean_absolute_error: 0.2008\n",
      "Epoch 4/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2165 - mean_absolute_error: 0.1757 - val_loss: 0.2463 - val_mean_absolute_error: 0.1955\n",
      "Epoch 5/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1819 - mean_absolute_error: 0.1478 - val_loss: 0.2609 - val_mean_absolute_error: 0.1977\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(train_features_np, train_targets_np,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=5,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - 2ms/step - loss: 0.2437 - mean_absolute_error: 0.1917\n",
      "Test RMSE: 0.24369201064109802, Test MAE: 0.1917336881160736\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "test_loss, test_mae = model.evaluate(test_features_np, test_targets_np, verbose=2)\n",
    "print(f\"Test RMSE: {test_loss}, Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelos/Beto.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_31_[4]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>No obstante, sería imprudente ejecutar un proy...</td>\n",
       "      <td>necesariamente</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_32_[2]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>La quiebra del capítulo 13 permanece en tus an...</td>\n",
       "      <td>antecedentes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_33_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Esta modalidad de cheques posfechados no es av...</td>\n",
       "      <td>legislación</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_34_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Para realizar el presupuesto, digamos finalmen...</td>\n",
       "      <td>aludido</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_35_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>De todas maneras, señala el Diccionario aludid...</td>\n",
       "      <td>computable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          en  english                                           sentence  \\\n",
       "0  es_31_[4]  spanish  No obstante, sería imprudente ejecutar un proy...   \n",
       "1  es_32_[2]  spanish  La quiebra del capítulo 13 permanece en tus an...   \n",
       "2  es_33_[1]  spanish  Esta modalidad de cheques posfechados no es av...   \n",
       "3  es_34_[1]  spanish  Para realizar el presupuesto, digamos finalmen...   \n",
       "4  es_35_[1]  spanish  De todas maneras, señala el Diccionario aludid...   \n",
       "\n",
       "      target_word  complexity  \n",
       "0  necesariamente         NaN  \n",
       "1    antecedentes         NaN  \n",
       "2     legislación         NaN  \n",
       "3         aludido         NaN  \n",
       "4      computable         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "input_file_path = '/home/spoturno/coding/MLSP_Data/Data/Test/Spanish/multilex_test_es_lcp_unlabelled.tsv'\n",
    "output_file_path = '/home/spoturno/coding/MLSP/predictions/beto_with_mlp.tsv'\n",
    "\n",
    "df = pd.read_csv(input_file_path, delimiter='\\t', header=None, names=['en', 'english', 'sentence', 'target_word', 'complexity'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 593/593 [00:25<00:00, 23.22it/s]\n",
      "Processing: 100%|██████████| 593/593 [00:14<00:00, 40.59it/s]\n"
     ]
    }
   ],
   "source": [
    "trial_set = process_dataframe(df, tokenizer, model_beto, device)\n",
    "trial_set = trial_set[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([593, 1536])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(trial_set.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complexity'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_31_[4]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>No obstante, sería imprudente ejecutar un proy...</td>\n",
       "      <td>necesariamente</td>\n",
       "      <td>0.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_32_[2]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>La quiebra del capítulo 13 permanece en tus an...</td>\n",
       "      <td>antecedentes</td>\n",
       "      <td>0.288554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_33_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Esta modalidad de cheques posfechados no es av...</td>\n",
       "      <td>legislación</td>\n",
       "      <td>0.316845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_34_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Para realizar el presupuesto, digamos finalmen...</td>\n",
       "      <td>aludido</td>\n",
       "      <td>0.291805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_35_[1]</td>\n",
       "      <td>spanish</td>\n",
       "      <td>De todas maneras, señala el Diccionario aludid...</td>\n",
       "      <td>computable</td>\n",
       "      <td>0.251362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>es_619</td>\n",
       "      <td>spanish</td>\n",
       "      <td>La función de concentración de recursos, tiene...</td>\n",
       "      <td>concentración</td>\n",
       "      <td>0.206668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>es_620</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Después surgió la moneda y posteriormente surg...</td>\n",
       "      <td>intercambios</td>\n",
       "      <td>0.260658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>es_621</td>\n",
       "      <td>spanish</td>\n",
       "      <td>A éstos se les coloca una fecha posterior al m...</td>\n",
       "      <td>suficientes</td>\n",
       "      <td>0.401528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>es_622</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Colisión: Choque de dos cuerpos. Oposición y p...</td>\n",
       "      <td>ahorro</td>\n",
       "      <td>0.255506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>es_623</td>\n",
       "      <td>spanish</td>\n",
       "      <td>La corrupción, en tanto, es lo opuesto a la ho...</td>\n",
       "      <td>soborno</td>\n",
       "      <td>0.428229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            en  english                                           sentence  \\\n",
       "0    es_31_[4]  spanish  No obstante, sería imprudente ejecutar un proy...   \n",
       "1    es_32_[2]  spanish  La quiebra del capítulo 13 permanece en tus an...   \n",
       "2    es_33_[1]  spanish  Esta modalidad de cheques posfechados no es av...   \n",
       "3    es_34_[1]  spanish  Para realizar el presupuesto, digamos finalmen...   \n",
       "4    es_35_[1]  spanish  De todas maneras, señala el Diccionario aludid...   \n",
       "..         ...      ...                                                ...   \n",
       "588     es_619  spanish  La función de concentración de recursos, tiene...   \n",
       "589     es_620  spanish  Después surgió la moneda y posteriormente surg...   \n",
       "590     es_621  spanish  A éstos se les coloca una fecha posterior al m...   \n",
       "591     es_622  spanish  Colisión: Choque de dos cuerpos. Oposición y p...   \n",
       "592     es_623  spanish  La corrupción, en tanto, es lo opuesto a la ho...   \n",
       "\n",
       "        target_word  complexity  \n",
       "0    necesariamente    0.281250  \n",
       "1      antecedentes    0.288554  \n",
       "2       legislación    0.316845  \n",
       "3           aludido    0.291805  \n",
       "4        computable    0.251362  \n",
       "..              ...         ...  \n",
       "588   concentración    0.206668  \n",
       "589    intercambios    0.260658  \n",
       "590     suficientes    0.401528  \n",
       "591          ahorro    0.255506  \n",
       "592         soborno    0.428229  \n",
       "\n",
       "[593 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file_path, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
