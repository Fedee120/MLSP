{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoturno/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/spoturno/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la oración: tensor([[ 6.3808e-01, -2.7869e-01, -1.9846e-01, -1.4776e-01,  3.0291e-01,\n",
      "          7.8052e-01,  9.3867e-02,  7.2238e-01, -4.6559e-02,  4.8533e-01,\n",
      "          1.1943e-01, -1.0878e+00,  3.5126e-01, -3.5981e-01,  4.9066e-01,\n",
      "         -7.4640e-01, -4.0938e-01, -1.9730e-01, -3.7721e-02,  1.0112e-01,\n",
      "          1.4318e-01,  5.2502e-02,  6.6922e-02, -1.2755e-01, -1.3663e-01,\n",
      "          5.8162e-03,  3.3418e-01, -8.0998e-02, -4.7620e-01, -8.3185e-02,\n",
      "          1.0710e-01,  1.7079e-01, -2.2541e-01,  4.2820e-01,  5.9104e-01,\n",
      "         -4.4022e-01,  1.2989e-02, -3.1058e-01, -3.8460e-01, -6.4842e-01,\n",
      "          1.3952e-01,  8.7414e-01,  7.6276e-01,  6.0126e-01, -3.9091e-02,\n",
      "          1.7234e-01, -1.6539e-01,  1.2365e-01,  1.5036e-01, -5.5027e-01,\n",
      "          3.2842e-01, -2.8708e-02, -3.6269e-01, -2.3796e-01,  6.1217e-01,\n",
      "         -1.7270e-02,  2.6563e-01,  1.4247e-01, -4.9820e-01,  5.1619e-01,\n",
      "          7.6938e-01,  2.9431e-01,  5.6767e-02, -3.4350e-01,  2.2901e-01,\n",
      "          5.4656e-02,  2.3299e-02,  1.1706e+00, -2.2197e-01, -4.5741e-02,\n",
      "          1.9164e-01, -6.7925e-01,  4.0971e-01, -1.4069e-01,  2.4823e-01,\n",
      "          4.2665e-01,  7.0757e-01,  6.5202e-01,  1.2250e-01, -4.8227e-01,\n",
      "         -3.6032e-01,  7.2380e-02,  3.7368e-01, -2.5553e-01,  3.8803e-01,\n",
      "         -5.3839e-01,  4.8072e-01, -1.2139e-01, -1.4491e-01,  1.6893e-01,\n",
      "          1.5740e-01,  2.1156e-01,  1.3272e-01, -1.4226e-01,  5.5756e-03,\n",
      "          1.7899e-01,  5.3654e-01, -1.0321e+00,  5.1885e-02,  7.3231e-01,\n",
      "         -6.2169e-01,  7.5915e-01, -2.2501e-01,  1.4842e-01,  5.8922e-01,\n",
      "         -1.2889e+00,  1.3390e+00, -4.0064e+00,  1.4241e-02,  1.8090e-01,\n",
      "          1.9464e-01,  2.2039e-01, -7.0445e-02,  6.1950e-01, -2.0448e-02,\n",
      "         -5.6913e-01,  2.9925e-01, -2.1818e-01,  7.2549e-02, -2.4494e-01,\n",
      "         -1.1951e-01,  8.0834e-01,  4.2676e-01, -2.1732e-01,  2.9969e-01,\n",
      "          8.9773e-01, -8.6717e-01,  3.8994e-01, -1.2665e-01, -1.6692e-01,\n",
      "         -1.0599e-01, -5.6337e-02, -8.2591e-02,  7.6812e-02,  3.4336e-01,\n",
      "         -4.5404e-02, -7.6241e-01, -2.5912e-01, -2.7373e-01,  3.4736e-01,\n",
      "         -3.4753e-01, -1.7161e-01,  2.5836e-01, -1.1668e-01, -1.4595e-01,\n",
      "         -2.2175e-01, -1.5376e-01,  5.5391e-01,  9.3630e-01, -4.8452e-01,\n",
      "          2.1175e-01, -1.4682e-01,  4.7808e-01, -5.0656e-01, -1.2057e+00,\n",
      "         -5.5471e-01, -5.0302e-01,  9.5998e-03,  2.7015e-01, -3.9098e-01,\n",
      "         -3.2245e-01, -1.0414e+00,  9.1437e-02,  2.1166e-01,  9.2383e-01,\n",
      "         -2.1255e-01,  6.6813e-01, -3.1040e-01,  1.2391e-01,  2.2823e-01,\n",
      "         -2.3198e-02, -4.8228e-01, -2.2351e-02,  3.3493e-01,  7.6900e-02,\n",
      "          4.1524e-01, -9.3357e-01,  2.2505e-02,  2.2392e-01, -2.2260e-01,\n",
      "          5.6802e-02, -1.3709e-01,  7.0215e-01, -4.5397e-01, -8.8421e-01,\n",
      "          3.2224e-02,  1.5049e-01, -2.6566e-01,  4.1688e-01, -7.2681e-01,\n",
      "          6.9483e-01, -2.9294e-01,  6.2604e-01, -3.3036e-02, -7.1221e-01,\n",
      "         -4.6875e-01, -3.3098e-01,  3.9842e-01, -3.8021e-01, -1.5473e-01,\n",
      "          3.2529e-02,  9.7418e-02,  4.4325e-01,  5.4479e-01,  6.6691e-01,\n",
      "         -1.0978e+00, -1.0781e+00,  4.9045e-01, -4.8354e-01,  6.6540e-01,\n",
      "         -7.8275e+00,  8.6781e-03, -7.6373e-01,  2.7524e-01, -5.0699e-01,\n",
      "         -5.7288e-01,  3.8672e-02,  2.9521e-01, -4.9385e-01,  2.9906e-01,\n",
      "          8.2501e-01,  6.1131e-01,  7.1050e-02, -7.0987e-01,  3.9823e-02,\n",
      "         -4.9925e-01,  3.0317e-01, -1.2757e-01,  2.5798e-01,  6.5335e-01,\n",
      "          5.1779e-01, -7.5545e-01, -4.9763e-01,  1.6297e-01, -5.5971e-01,\n",
      "         -3.7077e-01, -4.4493e-01, -4.6171e-01, -8.2208e-01,  2.2162e-01,\n",
      "         -2.9789e-01,  3.2664e-01, -3.9860e-02, -8.6086e-02,  7.1386e-02,\n",
      "         -2.0408e-01,  3.4398e-01, -5.2662e-02,  1.1456e+00,  5.6476e-01,\n",
      "          1.6035e-01, -1.6578e-01,  1.5078e-01,  1.9845e-01, -8.2630e-01,\n",
      "         -1.2672e-01, -6.2279e-01,  4.2180e-02, -2.0963e-01,  8.7844e-02,\n",
      "         -6.5942e-01, -1.4892e-02,  1.4663e-01, -3.6777e-01, -6.4045e-01,\n",
      "         -4.1120e-01,  1.3506e-01, -9.4383e-01,  4.0475e-02,  1.4832e-01,\n",
      "          5.2396e-01,  8.5694e-02, -4.0860e-01, -2.8137e-01,  4.6750e-01,\n",
      "          6.6220e-01, -5.6247e-01,  1.5153e-01, -1.2745e+00, -1.5793e-01,\n",
      "          6.3491e-01, -1.9560e-01, -7.2376e-02, -3.6094e-01,  1.1569e+00,\n",
      "          6.6760e-02,  1.5512e-01, -6.6474e-01,  8.1394e-01, -2.9771e-01,\n",
      "          2.8309e-01,  7.1780e-01, -3.2355e-01,  3.6398e-02,  4.9835e-01,\n",
      "         -2.9194e-01, -3.5746e-01, -3.7116e-01, -2.4371e-01,  7.4604e-02,\n",
      "          4.2429e-01,  2.1011e-01,  7.8312e-01,  1.0137e+00, -1.0154e-01,\n",
      "         -1.3172e+00, -4.9552e-01, -1.7311e-01,  7.6277e-01, -1.1519e-01,\n",
      "          2.9938e-03,  1.3672e+00, -5.7322e-01, -2.8622e-01, -9.3774e-01,\n",
      "          2.3243e-01,  9.0775e-01, -2.4358e-01,  2.0115e-02,  7.9544e-01,\n",
      "         -3.6549e-01,  5.0045e-01, -4.3227e-01, -8.5439e-02, -1.6560e-01,\n",
      "          5.6072e-01,  9.0131e-03, -7.4546e-03, -6.3031e-02, -4.1155e-01,\n",
      "         -3.9937e-01, -4.0248e-01, -3.8819e-01,  4.1991e-01, -8.7178e-01,\n",
      "          1.8228e-01,  3.2383e-01,  1.5685e-01, -5.8409e-02,  1.1671e-01,\n",
      "         -7.1548e-01, -2.4745e-01, -9.2137e-01, -3.8144e-01, -1.0827e-01,\n",
      "          8.1273e-01,  2.4611e-01, -2.4674e-01, -3.4113e-01, -7.7706e-02,\n",
      "         -3.0468e-01,  7.1060e-01, -2.7726e-01, -1.3786e-02,  2.2712e-01,\n",
      "         -4.0661e-01,  9.1332e-01, -1.3161e-01, -4.1692e-01,  1.4584e-01,\n",
      "         -4.5732e-01, -1.5027e-01, -2.4169e-01,  4.7510e-01,  8.3916e-01,\n",
      "          9.2846e-02,  2.1201e-01, -5.4225e-01, -2.3003e-01,  3.3851e-01,\n",
      "          2.3205e-01, -1.9417e-01, -6.2825e-01,  1.0929e+00,  3.5012e-01,\n",
      "         -9.4771e-01, -2.7600e-01,  1.4746e-01, -5.1019e-01, -4.2050e-01,\n",
      "          7.1478e-01,  1.1583e-01, -2.8069e-01,  9.2157e-01,  6.6598e-01,\n",
      "          2.5757e-01,  7.2573e-01,  1.9109e-02, -8.1637e-02,  5.4996e-02,\n",
      "         -8.1388e-01,  5.9317e-02, -5.1855e-01,  2.4748e-01,  6.2133e-01,\n",
      "         -4.7652e-01,  5.7810e-01, -7.0429e-01,  2.1585e-01,  4.1991e-03,\n",
      "         -6.0368e-02, -2.6762e-01, -2.8412e-01,  9.9581e-01, -4.1445e-01,\n",
      "          1.7067e-01,  5.3563e-01, -8.8334e-01, -3.7551e-02,  3.7808e-01,\n",
      "         -3.0806e-01, -4.3462e-01, -2.4872e-01, -7.9498e-01, -3.5213e-01,\n",
      "         -6.6024e-01,  1.9848e+00, -1.0408e-01,  8.1906e-01,  5.3999e-01,\n",
      "          7.8591e-02, -2.1554e-01, -3.1655e-01, -2.8681e-01,  3.7454e-02,\n",
      "          1.0827e+00,  6.6591e-02, -3.7314e-01,  7.9348e-01, -3.2858e-01,\n",
      "          1.7873e-03, -2.0592e-01, -3.8491e-01, -3.3109e-01,  4.0256e-01,\n",
      "         -2.1940e-01, -8.5931e-02, -5.7942e-03, -1.6313e-02,  1.3511e+00,\n",
      "          1.2449e-01,  3.5120e-01, -3.3516e-01, -2.7821e-01,  4.6984e-01,\n",
      "          1.0429e+00, -9.6334e-02,  2.4260e-01,  6.6188e-01, -6.3377e-01,\n",
      "         -5.1635e-01, -3.1616e-01,  1.7234e-01,  4.1077e-01,  1.0183e+00,\n",
      "         -1.0201e+00, -3.5696e-01, -5.8011e-01,  7.7932e-02, -2.7776e-01,\n",
      "         -7.1787e-01, -2.1158e-02, -4.4824e-01, -1.8083e+00,  1.5637e-01,\n",
      "         -3.4993e-01, -9.8394e-01, -1.5196e+00, -6.4687e-01,  1.9200e-01,\n",
      "         -2.4309e-01, -4.9047e-01, -1.3052e-01,  4.1982e-01,  3.1081e-01,\n",
      "         -2.2139e-01,  1.6260e-01,  1.0822e+00, -4.8573e-01, -3.3474e-01,\n",
      "         -5.4293e-01,  9.8519e-02, -4.4120e-02, -6.8845e-02,  5.0290e-01,\n",
      "         -1.1181e+00,  7.4030e-01,  3.4272e-01,  1.3267e-01,  9.2568e-01,\n",
      "         -5.9526e-01,  1.7963e-01,  1.9069e-01,  6.8897e-01, -2.4926e-01,\n",
      "         -9.2334e-02,  3.6767e-01, -8.9961e-01, -1.2001e-01,  1.0166e+00,\n",
      "          2.9566e-01, -1.2209e-01,  4.6631e-01, -5.8352e-01, -1.5718e-01,\n",
      "         -4.8561e-01, -4.9386e-01, -5.5439e-01,  3.1279e-01, -2.8687e-01,\n",
      "         -1.9980e-01,  1.2368e-01,  1.0087e+00,  5.6568e-01,  3.5183e-01,\n",
      "         -3.4965e-01, -3.9853e-01,  1.1129e-01,  4.8556e-01, -1.1497e-01,\n",
      "          3.6731e-01,  5.0054e-01,  1.3235e-01, -5.9355e-02,  4.6088e-01,\n",
      "         -5.9733e-01,  2.1210e-01,  1.8985e-01, -9.0318e-03, -3.7408e-01,\n",
      "          2.6082e-01,  1.8206e-01,  2.3124e-01, -1.2320e+00, -1.6051e-01,\n",
      "          5.9191e-02,  1.0951e+00, -5.1247e-01, -2.0456e-01, -5.2713e-01,\n",
      "          5.1566e-01, -9.1212e-01,  4.5276e-01, -7.2890e-02, -1.8373e-01,\n",
      "          2.6283e-01, -1.1056e-01,  2.6262e-02, -2.2802e-01, -8.4689e-01,\n",
      "         -6.3462e-01, -2.0660e-01,  3.1066e-01,  7.5166e-03, -3.0515e-01,\n",
      "         -1.7981e-01, -4.3573e-01,  1.1606e-01, -1.1255e+01, -6.9296e-01,\n",
      "          6.6084e-01, -1.1098e-01, -5.8800e-02,  4.1058e-02,  3.2083e-01,\n",
      "          1.8596e-01, -3.7057e-01, -5.0690e-01, -2.6233e-01,  2.9524e-01,\n",
      "          1.1924e+00, -5.3948e-01, -5.4173e-01, -4.0594e-01, -2.6519e-01,\n",
      "          2.7425e-01,  2.3026e-01, -8.4117e-02, -2.8083e-01, -5.6902e-02,\n",
      "         -6.3213e-01,  1.7367e-01,  4.2734e-01, -8.3956e-01,  3.2899e-01,\n",
      "         -1.1279e-01, -2.1048e-01,  8.8454e-01,  4.6722e-01, -4.7233e-01,\n",
      "         -4.3432e-03, -3.9956e-01,  8.3105e-01, -3.9797e-01, -1.0637e-01,\n",
      "          1.4452e-01,  1.6028e-01,  1.0159e-01, -6.0111e-01, -3.2069e-01,\n",
      "         -2.8888e-01,  1.5896e-01,  1.8503e-01,  4.8713e-01,  2.5445e-01,\n",
      "         -1.1287e-01, -4.6544e-02,  1.2215e+00,  9.8503e-01,  2.5347e-01,\n",
      "          1.0768e+00, -5.7689e-01,  1.9835e-01,  3.7738e-01,  4.4718e-01,\n",
      "          7.5543e-02, -5.8555e-02, -4.5640e-01, -4.8773e-01,  1.7591e-01,\n",
      "          2.2826e-01, -7.0500e-02, -1.1873e-01,  3.8637e-01, -2.4280e-02,\n",
      "         -3.0368e-01,  6.1115e-01, -1.3077e-01, -4.7276e-01, -9.3133e-01,\n",
      "         -2.0584e-01, -2.0808e-01, -1.4765e-01, -4.2222e-01, -9.4475e-01,\n",
      "         -7.0276e-01, -3.6335e-01,  4.0612e-01,  4.2297e-01, -4.7510e-01,\n",
      "         -3.3037e-02, -3.0712e-01,  6.9213e-02, -4.0996e-01, -1.1216e-01,\n",
      "         -8.0143e-01, -7.5459e-02, -1.7295e-02,  1.7895e-01,  7.7409e-02,\n",
      "         -5.3205e-01,  4.1488e-02,  6.7716e-01, -5.0974e-01,  4.8603e-01,\n",
      "          8.1466e-01,  5.8619e-01,  4.5293e-01,  6.2994e-01, -2.9320e-01,\n",
      "          1.1029e+00,  3.4106e-01,  3.2443e-01, -3.2732e-01, -2.7557e-01,\n",
      "          7.8236e-01, -6.1562e-01,  2.4784e-01,  4.3942e-01,  3.2014e-01,\n",
      "          8.4462e-01, -4.0970e-01,  3.3205e-02, -2.2592e-01, -6.1388e-02,\n",
      "          4.9428e-01,  3.5807e-01,  1.0452e+00, -2.5209e-02,  6.0836e-01,\n",
      "         -7.0606e-01,  6.1137e-01,  2.3412e-01, -6.2845e-01,  2.5340e-02,\n",
      "         -7.5225e-02,  2.1656e-01,  3.7654e-01, -4.3343e-01, -3.9244e-01,\n",
      "         -1.8053e-01,  7.8931e-01, -3.3529e-01, -4.8532e-01,  1.3169e-02,\n",
      "          2.9534e-02,  1.4241e-01,  2.8444e-02, -4.4112e-01, -9.3713e-01,\n",
      "          2.1299e-01, -1.6348e-01, -1.8427e-01, -6.5661e-02, -3.1764e-01,\n",
      "         -5.3278e-01,  2.2274e-01,  1.9805e-01,  2.2089e-01, -9.0776e-01,\n",
      "          2.8805e-01,  1.2338e+00,  1.0899e+00,  6.4805e-01,  7.0943e-01,\n",
      "          6.7203e-02,  1.0514e+00, -9.6491e-01, -5.2045e-01, -1.5405e-01,\n",
      "         -5.8397e-01,  2.1185e-01, -1.4337e+00, -4.6307e-01, -8.5101e-01,\n",
      "         -5.6044e-01,  4.9831e-01,  2.6793e-01, -9.0340e-01,  1.4603e-01,\n",
      "         -9.0344e-02, -5.6050e-01,  1.6341e-01, -2.1756e-02,  6.9088e-01,\n",
      "          8.3390e-01,  2.0623e-02, -4.1925e-01,  4.2609e-01, -1.6042e-01,\n",
      "          4.5718e-01,  1.0983e-01,  2.3367e-01,  2.1064e-01,  8.4254e-01,\n",
      "         -3.8998e-02, -7.5355e-02, -2.2032e-01,  1.3734e-01,  7.0637e-01,\n",
      "          9.7983e-02,  2.1374e-01,  5.2576e-02, -1.0675e+00, -2.3992e-01,\n",
      "         -2.5484e-01,  9.7701e-01, -6.2863e-01,  4.4528e-01, -1.0535e+00,\n",
      "         -2.7687e-01, -3.5165e-01, -3.8038e-01,  2.5838e-02,  9.0959e-01,\n",
      "          2.1218e-01,  1.3388e-01,  1.4071e-01]])\n",
      "Embeddings de las palabras: tensor([[[ 0.6381, -0.2787, -0.1985,  ...,  0.2122,  0.1339,  0.1407],\n",
      "         [ 0.4672, -0.3835, -0.2334,  ..., -0.1781, -0.5380,  0.2391],\n",
      "         [-0.1892,  0.3194, -0.3417,  ...,  0.0925, -0.7950,  0.0272],\n",
      "         ...,\n",
      "         [ 0.4276,  0.0904, -0.0048,  ...,  0.3439,  0.1649,  0.4735],\n",
      "         [-0.0356,  0.3053, -0.0507,  ...,  0.1680,  0.1654, -0.1134],\n",
      "         [-0.5077, -0.3374, -0.7238,  ..., -0.1003, -0.3568,  0.2244]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Carga el tokenizador y el modelo BETO\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model_beto = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "# Oración de ejemplo\n",
    "sentence = \"Hola, esto es una prueba con BERT.\"\n",
    "\n",
    "# Tokeniza la oración\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Obtiene los embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model_beto(**inputs)\n",
    "\n",
    "# Los embeddings de la última capa oculta serían\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Embedding del [CLS] token que representa la oración entera\n",
    "sentence_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "# Embeddings de cada token/palabra en la oración\n",
    "word_embeddings = last_hidden_states\n",
    "\n",
    "print(\"Embedding de la oración:\", sentence_embedding)\n",
    "print(\"Embeddings de las palabras:\", word_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/data_mlsp_fing.csv', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>palabraCompleja</th>\n",
       "      <th>evaluacion_normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             oracion palabraCompleja  \\\n",
       "0                trabajo abnegado de los sanitarios         abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...   paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...      incidencia   \n",
       "3  Es la primera vez que me toca participar en un...     autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...            seno   \n",
       "\n",
       "   evaluacion_normalizada  \n",
       "0                     3.0  \n",
       "1                     4.0  \n",
       "2                     1.5  \n",
       "3                     3.0  \n",
       "4                     2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         3.0  \n",
       "1         4.0  \n",
       "2         1.5  \n",
       "3         3.0  \n",
       "4         2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.rename(columns={'oracion': 'sentence', 'palabraCompleja': 'target_word', 'evaluacion_normalizada': 'complexity'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizemos la columna de complexity dividiendo entre 5 todo\n",
    "df['complexity'] = df['complexity']/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigmático</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es además una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigmático   \n",
       "2  Es además una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         0.6  \n",
       "1         0.8  \n",
       "2         0.3  \n",
       "3         0.6  \n",
       "4         0.4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check for cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_beto.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1859/1859 [01:42<00:00, 18.08it/s]\n",
      "Processing: 100%|██████████| 1859/1859 [00:56<00:00, 33.02it/s]\n",
      "Processing: 100%|██████████| 465/465 [00:26<00:00, 17.75it/s]\n",
      "Processing: 100%|██████████| 465/465 [00:14<00:00, 32.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que df es tu DataFrame que incluye las columnas 'sentence', 'target_word' y 'complexity'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embeddings(text_list, tokenizer, model, device):\n",
    "    \"\"\"Obtiene embeddings [CLS] para una lista de textos, con barra de progreso.\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=\"Processing\", leave=True):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu())\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "\n",
    "def process_dataframe(df, tokenizer, model, device):\n",
    "    \"\"\"Procesa un dataframe para obtener embeddings y complejidades.\"\"\"\n",
    "    sentence_embeddings = get_embeddings(df['sentence'].tolist(), tokenizer, model, device)\n",
    "    word_embeddings = get_embeddings(df['target_word'].tolist(), tokenizer, model, device)\n",
    "    complexities = torch.tensor(df['complexity'].values, dtype=torch.float).unsqueeze(1)\n",
    "    return torch.cat((sentence_embeddings, word_embeddings, complexities), dim=1)\n",
    "\n",
    "# Procesar los conjuntos de entrenamiento y prueba\n",
    "train_data = process_dataframe(train_df, tokenizer, model_beto, device)\n",
    "test_data = process_dataframe(test_df, tokenizer, model_beto, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1859, 1537]), torch.Size([465, 1537]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de entrenamiento (todas las columnas excepto la última)\n",
    "train_features = train_data[:, :-1]\n",
    "# Objetivos de entrenamiento (última columna)\n",
    "train_targets = train_data[:, -1]\n",
    "\n",
    "# Entradas de prueba\n",
    "test_features = test_data[:, :-1]\n",
    "# Objetivos de prueba\n",
    "test_targets = test_data[:, -1]\n",
    "\n",
    "# Asegúrate de que los tensores estén en la CPU para convertirlos a arrays de NumPy\n",
    "train_features_np = train_features.numpy()\n",
    "train_targets_np = train_targets.numpy()\n",
    "test_features_np = test_features.numpy()\n",
    "test_targets_np = test_targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 18:55:40.598908: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 18:55:40.599167: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 18:55:40.601370: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 18:55:40.626575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 18:55:41.158180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoturno/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m393,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=rmse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5558 - mean_absolute_error: 0.4920 - val_loss: 0.2487 - val_mean_absolute_error: 0.1996\n",
      "Epoch 2/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2410 - mean_absolute_error: 0.1978 - val_loss: 0.2424 - val_mean_absolute_error: 0.1969\n",
      "Epoch 3/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2172 - mean_absolute_error: 0.1732 - val_loss: 0.2415 - val_mean_absolute_error: 0.1980\n",
      "Epoch 4/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2022 - mean_absolute_error: 0.1622 - val_loss: 0.2517 - val_mean_absolute_error: 0.2005\n",
      "Epoch 5/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2026 - mean_absolute_error: 0.1612 - val_loss: 0.2687 - val_mean_absolute_error: 0.2054\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(train_features_np, train_targets_np,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=5,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - 1ms/step - loss: 0.2433 - mean_absolute_error: 0.1923\n",
      "Test RMSE: 0.24329641461372375, Test MAE: 0.19230590760707855\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "test_loss, test_mae = model.evaluate(test_features_np, test_targets_np, verbose=2)\n",
    "print(f\"Test RMSE: {test_loss}, Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelos/Beto.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Notifique a su Banco o institución financiera ...</td>\n",
       "      <td>notifique</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_2</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>sueldos</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_3</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>amenazar</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_4</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>ocasiona</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_5</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Cuando se visita a los norteamericanos y se es...</td>\n",
       "      <td>norteamericanos</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     en  english                                           sentence  \\\n",
       "0  es_1  spanish  Notifique a su Banco o institución financiera ...   \n",
       "1  es_2  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "2  es_3  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "3  es_4  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "4  es_5  spanish  Cuando se visita a los norteamericanos y se es...   \n",
       "\n",
       "        target_word  complexity  \n",
       "0         notifique       0.450  \n",
       "1          sueldos        0.225  \n",
       "2         amenazar        0.575  \n",
       "3         ocasiona        0.575  \n",
       "4  norteamericanos        0.150  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "input_file_path = '/home/spoturno/coding/MLSP_Data/Data/Trial/Spanish/multilex_trial_es_lcp.tsv'\n",
    "output_file_path = input_file_path.replace('.tsv', '_results.csv')\n",
    "\n",
    "df = pd.read_csv(input_file_path, delimiter='\\t', header=None, names=['en', 'english', 'sentence', 'target_word', 'complexity'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:01<00:00, 19.48it/s]\n",
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 35.11it/s]\n"
     ]
    }
   ],
   "source": [
    "trial_set = process_dataframe(df, tokenizer, model_beto, device)\n",
    "trial_set = trial_set[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(trial_set.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31075418],\n",
       "       [0.1860368 ],\n",
       "       [0.2870497 ],\n",
       "       [0.16819888],\n",
       "       [0.313484  ],\n",
       "       [0.4292397 ],\n",
       "       [0.40438223],\n",
       "       [0.36227912],\n",
       "       [0.40441304],\n",
       "       [0.33298883],\n",
       "       [0.289402  ],\n",
       "       [0.2841792 ],\n",
       "       [0.35151643],\n",
       "       [0.2934751 ],\n",
       "       [0.20819339],\n",
       "       [0.2374098 ],\n",
       "       [0.292369  ],\n",
       "       [0.32097536],\n",
       "       [0.26388097],\n",
       "       [0.2576243 ],\n",
       "       [0.17913207],\n",
       "       [0.37311977],\n",
       "       [0.10950947],\n",
       "       [0.28669083],\n",
       "       [0.3322345 ],\n",
       "       [0.3000164 ],\n",
       "       [0.55594456],\n",
       "       [0.41000155],\n",
       "       [0.19340724],\n",
       "       [0.4658618 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complexity'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Notifique a su Banco o institución financiera ...</td>\n",
       "      <td>notifique</td>\n",
       "      <td>0.310754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_2</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>sueldos</td>\n",
       "      <td>0.186037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_3</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>amenazar</td>\n",
       "      <td>0.287050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_4</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Una falta de liquidez ocasiona problemas que p...</td>\n",
       "      <td>ocasiona</td>\n",
       "      <td>0.168199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_5</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Cuando se visita a los norteamericanos y se es...</td>\n",
       "      <td>norteamericanos</td>\n",
       "      <td>0.313484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es_6</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Cuando se visita a los norteamericanos y se es...</td>\n",
       "      <td>desvíos</td>\n",
       "      <td>0.429240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>es_7</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Cuando se visita a los norteamericanos y se es...</td>\n",
       "      <td>legistas</td>\n",
       "      <td>0.404382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>es_8</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Dicha prosperidad o seguridad está estrechamen...</td>\n",
       "      <td>sustituto</td>\n",
       "      <td>0.362279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>es_9</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Dicha prosperidad o seguridad está estrechamen...</td>\n",
       "      <td>vinculada</td>\n",
       "      <td>0.404413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>es_10</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Dicha prosperidad o seguridad está estrechamen...</td>\n",
       "      <td>dicha</td>\n",
       "      <td>0.332989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>es_11</td>\n",
       "      <td>spanish</td>\n",
       "      <td>El único estado que no exige el seguro de resp...</td>\n",
       "      <td>fondos</td>\n",
       "      <td>0.289402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>es_12</td>\n",
       "      <td>spanish</td>\n",
       "      <td>El único estado que no exige el seguro de resp...</td>\n",
       "      <td>exige</td>\n",
       "      <td>0.284179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>es_13</td>\n",
       "      <td>spanish</td>\n",
       "      <td>El único estado que no exige el seguro de resp...</td>\n",
       "      <td>demuestren</td>\n",
       "      <td>0.351516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>es_14</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Las comunidades dependen de la producción de b...</td>\n",
       "      <td>producidos</td>\n",
       "      <td>0.293475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>es_15</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Las comunidades dependen de la producción de b...</td>\n",
       "      <td>comunidades</td>\n",
       "      <td>0.208193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>es_16</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Las comunidades dependen de la producción de b...</td>\n",
       "      <td>equilibradamente</td>\n",
       "      <td>0.237410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>es_17</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los documentos debe archivarlos en fólderes o ...</td>\n",
       "      <td>carpeta</td>\n",
       "      <td>0.292369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>es_18</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los documentos debe archivarlos en fólderes o ...</td>\n",
       "      <td>archivarlo</td>\n",
       "      <td>0.320975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>es_19</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los documentos debe archivarlos en fólderes o ...</td>\n",
       "      <td>archivador</td>\n",
       "      <td>0.263881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>es_20</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los seguros son una modalidad de gestión finan...</td>\n",
       "      <td>prevenir</td>\n",
       "      <td>0.257624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>es_21</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los seguros son una modalidad de gestión finan...</td>\n",
       "      <td>modalidad</td>\n",
       "      <td>0.179132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>es_22</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Los seguros son una modalidad de gestión finan...</td>\n",
       "      <td>descalabros</td>\n",
       "      <td>0.373120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>es_23</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Notifique a su Banco o institución financiera ...</td>\n",
       "      <td>utilizando</td>\n",
       "      <td>0.109509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>es_24</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Notifique a su Banco o institución financiera ...</td>\n",
       "      <td>chequeras</td>\n",
       "      <td>0.286691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>es_25</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Pueden estar colmados de desbarajustes y el bi...</td>\n",
       "      <td>acostumbraron</td>\n",
       "      <td>0.332235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>es_26</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Pueden estar colmados de desbarajustes y el bi...</td>\n",
       "      <td>colmados</td>\n",
       "      <td>0.300016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>es_27</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Pueden estar colmados de desbarajustes y el bi...</td>\n",
       "      <td>desbarajustes</td>\n",
       "      <td>0.555945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>es_28</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Y le va a presentar algunos retos personales p...</td>\n",
       "      <td>esperaría</td>\n",
       "      <td>0.410002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>es_29</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Y le va a presentar algunos retos personales p...</td>\n",
       "      <td>retos</td>\n",
       "      <td>0.193407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>es_30</td>\n",
       "      <td>spanish</td>\n",
       "      <td>Y le va a presentar algunos retos personales p...</td>\n",
       "      <td>lúgubre</td>\n",
       "      <td>0.465862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       en  english                                           sentence  \\\n",
       "0    es_1  spanish  Notifique a su Banco o institución financiera ...   \n",
       "1    es_2  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "2    es_3  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "3    es_4  spanish  Una falta de liquidez ocasiona problemas que p...   \n",
       "4    es_5  spanish  Cuando se visita a los norteamericanos y se es...   \n",
       "5    es_6  spanish  Cuando se visita a los norteamericanos y se es...   \n",
       "6    es_7  spanish  Cuando se visita a los norteamericanos y se es...   \n",
       "7    es_8  spanish  Dicha prosperidad o seguridad está estrechamen...   \n",
       "8    es_9  spanish  Dicha prosperidad o seguridad está estrechamen...   \n",
       "9   es_10  spanish  Dicha prosperidad o seguridad está estrechamen...   \n",
       "10  es_11  spanish  El único estado que no exige el seguro de resp...   \n",
       "11  es_12  spanish  El único estado que no exige el seguro de resp...   \n",
       "12  es_13  spanish  El único estado que no exige el seguro de resp...   \n",
       "13  es_14  spanish  Las comunidades dependen de la producción de b...   \n",
       "14  es_15  spanish  Las comunidades dependen de la producción de b...   \n",
       "15  es_16  spanish  Las comunidades dependen de la producción de b...   \n",
       "16  es_17  spanish  Los documentos debe archivarlos en fólderes o ...   \n",
       "17  es_18  spanish  Los documentos debe archivarlos en fólderes o ...   \n",
       "18  es_19  spanish  Los documentos debe archivarlos en fólderes o ...   \n",
       "19  es_20  spanish  Los seguros son una modalidad de gestión finan...   \n",
       "20  es_21  spanish  Los seguros son una modalidad de gestión finan...   \n",
       "21  es_22  spanish  Los seguros son una modalidad de gestión finan...   \n",
       "22  es_23  spanish  Notifique a su Banco o institución financiera ...   \n",
       "23  es_24  spanish  Notifique a su Banco o institución financiera ...   \n",
       "24  es_25  spanish  Pueden estar colmados de desbarajustes y el bi...   \n",
       "25  es_26  spanish  Pueden estar colmados de desbarajustes y el bi...   \n",
       "26  es_27  spanish  Pueden estar colmados de desbarajustes y el bi...   \n",
       "27  es_28  spanish  Y le va a presentar algunos retos personales p...   \n",
       "28  es_29  spanish  Y le va a presentar algunos retos personales p...   \n",
       "29  es_30  spanish  Y le va a presentar algunos retos personales p...   \n",
       "\n",
       "          target_word  complexity  \n",
       "0           notifique    0.310754  \n",
       "1            sueldos     0.186037  \n",
       "2           amenazar     0.287050  \n",
       "3           ocasiona     0.168199  \n",
       "4    norteamericanos     0.313484  \n",
       "5            desvíos     0.429240  \n",
       "6           legistas     0.404382  \n",
       "7          sustituto     0.362279  \n",
       "8          vinculada     0.404413  \n",
       "9              dicha     0.332989  \n",
       "10            fondos     0.289402  \n",
       "11             exige     0.284179  \n",
       "12        demuestren     0.351516  \n",
       "13        producidos     0.293475  \n",
       "14       comunidades     0.208193  \n",
       "15  equilibradamente     0.237410  \n",
       "16           carpeta     0.292369  \n",
       "17        archivarlo     0.320975  \n",
       "18        archivador     0.263881  \n",
       "19          prevenir     0.257624  \n",
       "20         modalidad     0.179132  \n",
       "21       descalabros     0.373120  \n",
       "22        utilizando     0.109509  \n",
       "23         chequeras     0.286691  \n",
       "24     acostumbraron     0.332235  \n",
       "25          colmados     0.300016  \n",
       "26     desbarajustes     0.555945  \n",
       "27         esperaría     0.410002  \n",
       "28             retos     0.193407  \n",
       "29           lúgubre     0.465862  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/spoturno/coding/MLSP/metrics/beto_with_mlp/predictiones.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2493992782667985"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(0.0622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
