{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\59899\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la oraci√≥n: tensor([[ 6.3808e-01, -2.7869e-01, -1.9846e-01, -1.4776e-01,  3.0291e-01,\n",
      "          7.8052e-01,  9.3868e-02,  7.2238e-01, -4.6559e-02,  4.8533e-01,\n",
      "          1.1943e-01, -1.0878e+00,  3.5126e-01, -3.5981e-01,  4.9066e-01,\n",
      "         -7.4640e-01, -4.0938e-01, -1.9730e-01, -3.7720e-02,  1.0112e-01,\n",
      "          1.4318e-01,  5.2500e-02,  6.6923e-02, -1.2755e-01, -1.3663e-01,\n",
      "          5.8170e-03,  3.3418e-01, -8.0998e-02, -4.7620e-01, -8.3185e-02,\n",
      "          1.0710e-01,  1.7079e-01, -2.2541e-01,  4.2820e-01,  5.9105e-01,\n",
      "         -4.4022e-01,  1.2990e-02, -3.1058e-01, -3.8460e-01, -6.4842e-01,\n",
      "          1.3952e-01,  8.7414e-01,  7.6276e-01,  6.0126e-01, -3.9091e-02,\n",
      "          1.7234e-01, -1.6539e-01,  1.2365e-01,  1.5036e-01, -5.5027e-01,\n",
      "          3.2842e-01, -2.8707e-02, -3.6269e-01, -2.3796e-01,  6.1217e-01,\n",
      "         -1.7271e-02,  2.6562e-01,  1.4247e-01, -4.9820e-01,  5.1619e-01,\n",
      "          7.6938e-01,  2.9431e-01,  5.6766e-02, -3.4350e-01,  2.2901e-01,\n",
      "          5.4657e-02,  2.3299e-02,  1.1707e+00, -2.2197e-01, -4.5741e-02,\n",
      "          1.9164e-01, -6.7926e-01,  4.0971e-01, -1.4069e-01,  2.4823e-01,\n",
      "          4.2665e-01,  7.0757e-01,  6.5201e-01,  1.2251e-01, -4.8227e-01,\n",
      "         -3.6032e-01,  7.2380e-02,  3.7368e-01, -2.5553e-01,  3.8803e-01,\n",
      "         -5.3839e-01,  4.8072e-01, -1.2139e-01, -1.4491e-01,  1.6893e-01,\n",
      "          1.5740e-01,  2.1156e-01,  1.3272e-01, -1.4226e-01,  5.5752e-03,\n",
      "          1.7899e-01,  5.3654e-01, -1.0321e+00,  5.1884e-02,  7.3231e-01,\n",
      "         -6.2169e-01,  7.5915e-01, -2.2501e-01,  1.4842e-01,  5.8922e-01,\n",
      "         -1.2889e+00,  1.3390e+00, -4.0064e+00,  1.4241e-02,  1.8090e-01,\n",
      "          1.9464e-01,  2.2039e-01, -7.0446e-02,  6.1950e-01, -2.0449e-02,\n",
      "         -5.6913e-01,  2.9925e-01, -2.1818e-01,  7.2551e-02, -2.4494e-01,\n",
      "         -1.1951e-01,  8.0834e-01,  4.2676e-01, -2.1732e-01,  2.9969e-01,\n",
      "          8.9773e-01, -8.6717e-01,  3.8994e-01, -1.2664e-01, -1.6692e-01,\n",
      "         -1.0599e-01, -5.6337e-02, -8.2591e-02,  7.6813e-02,  3.4336e-01,\n",
      "         -4.5405e-02, -7.6241e-01, -2.5912e-01, -2.7373e-01,  3.4736e-01,\n",
      "         -3.4753e-01, -1.7161e-01,  2.5836e-01, -1.1668e-01, -1.4595e-01,\n",
      "         -2.2175e-01, -1.5376e-01,  5.5391e-01,  9.3630e-01, -4.8452e-01,\n",
      "          2.1175e-01, -1.4682e-01,  4.7808e-01, -5.0656e-01, -1.2057e+00,\n",
      "         -5.5471e-01, -5.0302e-01,  9.5996e-03,  2.7015e-01, -3.9098e-01,\n",
      "         -3.2245e-01, -1.0414e+00,  9.1437e-02,  2.1166e-01,  9.2383e-01,\n",
      "         -2.1255e-01,  6.6813e-01, -3.1040e-01,  1.2391e-01,  2.2823e-01,\n",
      "         -2.3197e-02, -4.8227e-01, -2.2350e-02,  3.3493e-01,  7.6900e-02,\n",
      "          4.1524e-01, -9.3357e-01,  2.2505e-02,  2.2392e-01, -2.2260e-01,\n",
      "          5.6802e-02, -1.3709e-01,  7.0215e-01, -4.5397e-01, -8.8421e-01,\n",
      "          3.2223e-02,  1.5049e-01, -2.6566e-01,  4.1688e-01, -7.2681e-01,\n",
      "          6.9483e-01, -2.9294e-01,  6.2604e-01, -3.3036e-02, -7.1221e-01,\n",
      "         -4.6875e-01, -3.3098e-01,  3.9842e-01, -3.8021e-01, -1.5473e-01,\n",
      "          3.2529e-02,  9.7418e-02,  4.4325e-01,  5.4479e-01,  6.6691e-01,\n",
      "         -1.0978e+00, -1.0781e+00,  4.9045e-01, -4.8354e-01,  6.6540e-01,\n",
      "         -7.8275e+00,  8.6779e-03, -7.6373e-01,  2.7524e-01, -5.0699e-01,\n",
      "         -5.7288e-01,  3.8671e-02,  2.9521e-01, -4.9385e-01,  2.9906e-01,\n",
      "          8.2501e-01,  6.1131e-01,  7.1051e-02, -7.0987e-01,  3.9825e-02,\n",
      "         -4.9925e-01,  3.0317e-01, -1.2757e-01,  2.5798e-01,  6.5335e-01,\n",
      "          5.1779e-01, -7.5545e-01, -4.9763e-01,  1.6297e-01, -5.5971e-01,\n",
      "         -3.7077e-01, -4.4493e-01, -4.6171e-01, -8.2208e-01,  2.2162e-01,\n",
      "         -2.9789e-01,  3.2665e-01, -3.9860e-02, -8.6087e-02,  7.1387e-02,\n",
      "         -2.0408e-01,  3.4398e-01, -5.2661e-02,  1.1456e+00,  5.6476e-01,\n",
      "          1.6035e-01, -1.6578e-01,  1.5078e-01,  1.9845e-01, -8.2630e-01,\n",
      "         -1.2672e-01, -6.2279e-01,  4.2179e-02, -2.0964e-01,  8.7843e-02,\n",
      "         -6.5943e-01, -1.4892e-02,  1.4663e-01, -3.6777e-01, -6.4045e-01,\n",
      "         -4.1120e-01,  1.3506e-01, -9.4383e-01,  4.0474e-02,  1.4832e-01,\n",
      "          5.2396e-01,  8.5693e-02, -4.0860e-01, -2.8137e-01,  4.6750e-01,\n",
      "          6.6220e-01, -5.6247e-01,  1.5153e-01, -1.2745e+00, -1.5793e-01,\n",
      "          6.3491e-01, -1.9559e-01, -7.2375e-02, -3.6094e-01,  1.1569e+00,\n",
      "          6.6760e-02,  1.5512e-01, -6.6474e-01,  8.1394e-01, -2.9771e-01,\n",
      "          2.8310e-01,  7.1780e-01, -3.2355e-01,  3.6398e-02,  4.9835e-01,\n",
      "         -2.9194e-01, -3.5746e-01, -3.7117e-01, -2.4371e-01,  7.4604e-02,\n",
      "          4.2429e-01,  2.1011e-01,  7.8312e-01,  1.0137e+00, -1.0154e-01,\n",
      "         -1.3172e+00, -4.9552e-01, -1.7311e-01,  7.6277e-01, -1.1519e-01,\n",
      "          2.9930e-03,  1.3672e+00, -5.7322e-01, -2.8623e-01, -9.3774e-01,\n",
      "          2.3243e-01,  9.0775e-01, -2.4358e-01,  2.0117e-02,  7.9544e-01,\n",
      "         -3.6549e-01,  5.0045e-01, -4.3227e-01, -8.5440e-02, -1.6560e-01,\n",
      "          5.6072e-01,  9.0135e-03, -7.4538e-03, -6.3032e-02, -4.1155e-01,\n",
      "         -3.9937e-01, -4.0248e-01, -3.8818e-01,  4.1991e-01, -8.7178e-01,\n",
      "          1.8228e-01,  3.2383e-01,  1.5685e-01, -5.8409e-02,  1.1671e-01,\n",
      "         -7.1549e-01, -2.4745e-01, -9.2137e-01, -3.8144e-01, -1.0827e-01,\n",
      "          8.1273e-01,  2.4610e-01, -2.4674e-01, -3.4113e-01, -7.7706e-02,\n",
      "         -3.0468e-01,  7.1060e-01, -2.7726e-01, -1.3786e-02,  2.2712e-01,\n",
      "         -4.0661e-01,  9.1332e-01, -1.3161e-01, -4.1692e-01,  1.4584e-01,\n",
      "         -4.5732e-01, -1.5027e-01, -2.4169e-01,  4.7510e-01,  8.3916e-01,\n",
      "          9.2846e-02,  2.1201e-01, -5.4225e-01, -2.3003e-01,  3.3851e-01,\n",
      "          2.3205e-01, -1.9417e-01, -6.2825e-01,  1.0929e+00,  3.5012e-01,\n",
      "         -9.4771e-01, -2.7600e-01,  1.4746e-01, -5.1019e-01, -4.2050e-01,\n",
      "          7.1478e-01,  1.1583e-01, -2.8069e-01,  9.2157e-01,  6.6598e-01,\n",
      "          2.5757e-01,  7.2573e-01,  1.9110e-02, -8.1636e-02,  5.4996e-02,\n",
      "         -8.1389e-01,  5.9316e-02, -5.1855e-01,  2.4748e-01,  6.2133e-01,\n",
      "         -4.7652e-01,  5.7810e-01, -7.0429e-01,  2.1585e-01,  4.1996e-03,\n",
      "         -6.0368e-02, -2.6762e-01, -2.8412e-01,  9.9581e-01, -4.1446e-01,\n",
      "          1.7067e-01,  5.3563e-01, -8.8334e-01, -3.7551e-02,  3.7808e-01,\n",
      "         -3.0806e-01, -4.3462e-01, -2.4872e-01, -7.9498e-01, -3.5213e-01,\n",
      "         -6.6024e-01,  1.9848e+00, -1.0408e-01,  8.1906e-01,  5.3999e-01,\n",
      "          7.8591e-02, -2.1554e-01, -3.1655e-01, -2.8681e-01,  3.7454e-02,\n",
      "          1.0827e+00,  6.6590e-02, -3.7314e-01,  7.9348e-01, -3.2858e-01,\n",
      "          1.7868e-03, -2.0592e-01, -3.8491e-01, -3.3109e-01,  4.0256e-01,\n",
      "         -2.1940e-01, -8.5930e-02, -5.7953e-03, -1.6313e-02,  1.3511e+00,\n",
      "          1.2449e-01,  3.5120e-01, -3.3516e-01, -2.7821e-01,  4.6984e-01,\n",
      "          1.0429e+00, -9.6333e-02,  2.4260e-01,  6.6188e-01, -6.3377e-01,\n",
      "         -5.1635e-01, -3.1616e-01,  1.7234e-01,  4.1077e-01,  1.0183e+00,\n",
      "         -1.0201e+00, -3.5696e-01, -5.8011e-01,  7.7932e-02, -2.7776e-01,\n",
      "         -7.1787e-01, -2.1158e-02, -4.4824e-01, -1.8083e+00,  1.5637e-01,\n",
      "         -3.4993e-01, -9.8394e-01, -1.5196e+00, -6.4687e-01,  1.9200e-01,\n",
      "         -2.4309e-01, -4.9047e-01, -1.3052e-01,  4.1982e-01,  3.1081e-01,\n",
      "         -2.2139e-01,  1.6260e-01,  1.0822e+00, -4.8573e-01, -3.3474e-01,\n",
      "         -5.4293e-01,  9.8518e-02, -4.4121e-02, -6.8845e-02,  5.0290e-01,\n",
      "         -1.1181e+00,  7.4030e-01,  3.4272e-01,  1.3267e-01,  9.2568e-01,\n",
      "         -5.9527e-01,  1.7963e-01,  1.9070e-01,  6.8897e-01, -2.4926e-01,\n",
      "         -9.2335e-02,  3.6767e-01, -8.9961e-01, -1.2001e-01,  1.0166e+00,\n",
      "          2.9566e-01, -1.2208e-01,  4.6631e-01, -5.8352e-01, -1.5718e-01,\n",
      "         -4.8561e-01, -4.9387e-01, -5.5439e-01,  3.1279e-01, -2.8687e-01,\n",
      "         -1.9980e-01,  1.2368e-01,  1.0087e+00,  5.6568e-01,  3.5183e-01,\n",
      "         -3.4964e-01, -3.9853e-01,  1.1129e-01,  4.8556e-01, -1.1497e-01,\n",
      "          3.6731e-01,  5.0054e-01,  1.3235e-01, -5.9355e-02,  4.6088e-01,\n",
      "         -5.9733e-01,  2.1210e-01,  1.8985e-01, -9.0316e-03, -3.7408e-01,\n",
      "          2.6082e-01,  1.8206e-01,  2.3124e-01, -1.2321e+00, -1.6051e-01,\n",
      "          5.9191e-02,  1.0951e+00, -5.1247e-01, -2.0456e-01, -5.2714e-01,\n",
      "          5.1566e-01, -9.1212e-01,  4.5276e-01, -7.2891e-02, -1.8373e-01,\n",
      "          2.6283e-01, -1.1057e-01,  2.6262e-02, -2.2802e-01, -8.4690e-01,\n",
      "         -6.3462e-01, -2.0660e-01,  3.1066e-01,  7.5169e-03, -3.0515e-01,\n",
      "         -1.7981e-01, -4.3573e-01,  1.1606e-01, -1.1255e+01, -6.9296e-01,\n",
      "          6.6085e-01, -1.1098e-01, -5.8799e-02,  4.1058e-02,  3.2083e-01,\n",
      "          1.8596e-01, -3.7057e-01, -5.0690e-01, -2.6233e-01,  2.9524e-01,\n",
      "          1.1924e+00, -5.3948e-01, -5.4173e-01, -4.0595e-01, -2.6519e-01,\n",
      "          2.7425e-01,  2.3026e-01, -8.4118e-02, -2.8084e-01, -5.6902e-02,\n",
      "         -6.3213e-01,  1.7367e-01,  4.2734e-01, -8.3956e-01,  3.2899e-01,\n",
      "         -1.1279e-01, -2.1048e-01,  8.8454e-01,  4.6722e-01, -4.7233e-01,\n",
      "         -4.3437e-03, -3.9956e-01,  8.3106e-01, -3.9797e-01, -1.0637e-01,\n",
      "          1.4452e-01,  1.6028e-01,  1.0159e-01, -6.0111e-01, -3.2069e-01,\n",
      "         -2.8888e-01,  1.5896e-01,  1.8503e-01,  4.8713e-01,  2.5445e-01,\n",
      "         -1.1287e-01, -4.6543e-02,  1.2215e+00,  9.8503e-01,  2.5347e-01,\n",
      "          1.0768e+00, -5.7690e-01,  1.9835e-01,  3.7738e-01,  4.4718e-01,\n",
      "          7.5543e-02, -5.8554e-02, -4.5640e-01, -4.8773e-01,  1.7591e-01,\n",
      "          2.2826e-01, -7.0501e-02, -1.1873e-01,  3.8637e-01, -2.4279e-02,\n",
      "         -3.0368e-01,  6.1115e-01, -1.3077e-01, -4.7276e-01, -9.3133e-01,\n",
      "         -2.0584e-01, -2.0808e-01, -1.4765e-01, -4.2222e-01, -9.4475e-01,\n",
      "         -7.0276e-01, -3.6335e-01,  4.0612e-01,  4.2297e-01, -4.7510e-01,\n",
      "         -3.3037e-02, -3.0713e-01,  6.9212e-02, -4.0996e-01, -1.1216e-01,\n",
      "         -8.0143e-01, -7.5458e-02, -1.7295e-02,  1.7895e-01,  7.7410e-02,\n",
      "         -5.3205e-01,  4.1489e-02,  6.7716e-01, -5.0974e-01,  4.8603e-01,\n",
      "          8.1467e-01,  5.8619e-01,  4.5293e-01,  6.2994e-01, -2.9320e-01,\n",
      "          1.1029e+00,  3.4106e-01,  3.2443e-01, -3.2732e-01, -2.7557e-01,\n",
      "          7.8236e-01, -6.1562e-01,  2.4784e-01,  4.3942e-01,  3.2014e-01,\n",
      "          8.4462e-01, -4.0970e-01,  3.3207e-02, -2.2592e-01, -6.1388e-02,\n",
      "          4.9428e-01,  3.5807e-01,  1.0452e+00, -2.5210e-02,  6.0836e-01,\n",
      "         -7.0606e-01,  6.1138e-01,  2.3412e-01, -6.2846e-01,  2.5340e-02,\n",
      "         -7.5225e-02,  2.1656e-01,  3.7653e-01, -4.3343e-01, -3.9244e-01,\n",
      "         -1.8052e-01,  7.8931e-01, -3.3529e-01, -4.8533e-01,  1.3170e-02,\n",
      "          2.9535e-02,  1.4241e-01,  2.8445e-02, -4.4112e-01, -9.3713e-01,\n",
      "          2.1299e-01, -1.6348e-01, -1.8427e-01, -6.5661e-02, -3.1764e-01,\n",
      "         -5.3278e-01,  2.2274e-01,  1.9805e-01,  2.2089e-01, -9.0776e-01,\n",
      "          2.8805e-01,  1.2338e+00,  1.0899e+00,  6.4805e-01,  7.0943e-01,\n",
      "          6.7202e-02,  1.0514e+00, -9.6491e-01, -5.2045e-01, -1.5405e-01,\n",
      "         -5.8397e-01,  2.1185e-01, -1.4337e+00, -4.6307e-01, -8.5101e-01,\n",
      "         -5.6044e-01,  4.9831e-01,  2.6793e-01, -9.0340e-01,  1.4603e-01,\n",
      "         -9.0344e-02, -5.6050e-01,  1.6341e-01, -2.1757e-02,  6.9088e-01,\n",
      "          8.3390e-01,  2.0623e-02, -4.1925e-01,  4.2609e-01, -1.6042e-01,\n",
      "          4.5718e-01,  1.0983e-01,  2.3367e-01,  2.1064e-01,  8.4254e-01,\n",
      "         -3.8998e-02, -7.5356e-02, -2.2032e-01,  1.3734e-01,  7.0637e-01,\n",
      "          9.7983e-02,  2.1374e-01,  5.2576e-02, -1.0675e+00, -2.3992e-01,\n",
      "         -2.5484e-01,  9.7701e-01, -6.2863e-01,  4.4528e-01, -1.0535e+00,\n",
      "         -2.7687e-01, -3.5165e-01, -3.8038e-01,  2.5838e-02,  9.0959e-01,\n",
      "          2.1218e-01,  1.3388e-01,  1.4071e-01]])\n",
      "Embeddings de las palabras: tensor([[[ 0.6381, -0.2787, -0.1985,  ...,  0.2122,  0.1339,  0.1407],\n",
      "         [ 0.4672, -0.3835, -0.2334,  ..., -0.1781, -0.5380,  0.2391],\n",
      "         [-0.1892,  0.3194, -0.3417,  ...,  0.0925, -0.7950,  0.0272],\n",
      "         ...,\n",
      "         [ 0.4276,  0.0904, -0.0048,  ...,  0.3439,  0.1649,  0.4735],\n",
      "         [-0.0356,  0.3053, -0.0507,  ...,  0.1680,  0.1654, -0.1134],\n",
      "         [-0.5077, -0.3374, -0.7238,  ..., -0.1003, -0.3568,  0.2244]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Carga el tokenizador y el modelo BETO\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "# Oraci√≥n de ejemplo\n",
    "sentence = \"Hola, esto es una prueba con BERT.\"\n",
    "\n",
    "# Tokeniza la oraci√≥n\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Obtiene los embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Los embeddings de la √∫ltima capa oculta ser√≠an\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Embedding del [CLS] token que representa la oraci√≥n entera\n",
    "sentence_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "# Embeddings de cada token/palabra en la oraci√≥n\n",
    "word_embeddings = last_hidden_states\n",
    "\n",
    "print(\"Embedding de la oraci√≥n:\", sentence_embedding)\n",
    "print(\"Embeddings de las palabras:\", word_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/data_mlsp_fing.csv', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oracion</th>\n",
       "      <th>palabraCompleja</th>\n",
       "      <th>evaluacion_normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigm√°tico</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es adem√°s una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             oracion palabraCompleja  \\\n",
       "0                trabajo abnegado de los sanitarios         abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...   paradigm√°tico   \n",
       "2  Es adem√°s una enfermedad que afecta a todos lo...      incidencia   \n",
       "3  Es la primera vez que me toca participar en un...     autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...            seno   \n",
       "\n",
       "   evaluacion_normalizada  \n",
       "0                     3.0  \n",
       "1                     4.0  \n",
       "2                     1.5  \n",
       "3                     3.0  \n",
       "4                     2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigm√°tico</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es adem√°s una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigm√°tico   \n",
       "2  Es adem√°s una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         3.0  \n",
       "1         4.0  \n",
       "2         1.5  \n",
       "3         3.0  \n",
       "4         2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.rename(columns={'oracion': 'sentence', 'palabraCompleja': 'target_word', 'evaluacion_normalizada': 'complexity'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizemos la columna de complexity dividiendo entre 5 todo\n",
    "df['complexity'] = df['complexity']/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trabajo abnegado de los sanitarios</td>\n",
       "      <td>abnegado</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El impacto de la X Solidaria es un ejemplo par...</td>\n",
       "      <td>paradigm√°tico</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es adem√°s una enfermedad que afecta a todos lo...</td>\n",
       "      <td>incidencia</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la primera vez que me toca participar en un...</td>\n",
       "      <td>autoridades</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es probable, por lo tanto, y al igual que ocur...</td>\n",
       "      <td>seno</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    target_word  \\\n",
       "0                trabajo abnegado de los sanitarios        abnegado   \n",
       "1  El impacto de la X Solidaria es un ejemplo par...  paradigm√°tico   \n",
       "2  Es adem√°s una enfermedad que afecta a todos lo...     incidencia   \n",
       "3  Es la primera vez que me toca participar en un...    autoridades   \n",
       "4  Es probable, por lo tanto, y al igual que ocur...           seno   \n",
       "\n",
       "   complexity  \n",
       "0         0.6  \n",
       "1         0.8  \n",
       "2         0.3  \n",
       "3         0.6  \n",
       "4         0.4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# check for cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/1859 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1859/1859 [00:22<00:00, 82.91it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1859/1859 [00:20<00:00, 89.76it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 465/465 [00:05<00:00, 83.34it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 465/465 [00:05<00:00, 89.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que df es tu DataFrame que incluye las columnas 'sentence', 'target_word' y 'complexity'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embeddings(text_list, tokenizer, model, device):\n",
    "    \"\"\"Obtiene embeddings [CLS] para una lista de textos, con barra de progreso.\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=\"Processing\", leave=True):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu())\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "\n",
    "def process_dataframe(df, tokenizer, model, device):\n",
    "    \"\"\"Procesa un dataframe para obtener embeddings y complejidades.\"\"\"\n",
    "    sentence_embeddings = get_embeddings(df['sentence'].tolist(), tokenizer, model, device)\n",
    "    word_embeddings = get_embeddings(df['target_word'].tolist(), tokenizer, model, device)\n",
    "    complexities = torch.tensor(df['complexity'].values, dtype=torch.float).unsqueeze(1)\n",
    "    return torch.cat((sentence_embeddings, word_embeddings, complexities), dim=1)\n",
    "\n",
    "# Procesar los conjuntos de entrenamiento y prueba\n",
    "train_data = process_dataframe(train_df, tokenizer, model, device)\n",
    "test_data = process_dataframe(test_df, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1859, 1537]), torch.Size([465, 1537]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de entrenamiento (todas las columnas excepto la √∫ltima)\n",
    "train_features = train_data[:, :-1]\n",
    "# Objetivos de entrenamiento (√∫ltima columna)\n",
    "train_targets = train_data[:, -1]\n",
    "\n",
    "# Entradas de prueba\n",
    "test_features = test_data[:, :-1]\n",
    "# Objetivos de prueba\n",
    "test_targets = test_data[:, -1]\n",
    "\n",
    "# Aseg√∫rate de que los tensores est√©n en la CPU para convertirlos a arrays de NumPy\n",
    "train_features_np = train_features.numpy()\n",
    "train_targets_np = train_targets.numpy()\n",
    "test_features_np = test_features.numpy()\n",
    "test_targets_np = test_targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\59899\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ       \u001b[38;5;34m393,472\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ        \u001b[38;5;34m32,896\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m129\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=rmse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4691 - mean_absolute_error: 0.3962 - val_loss: 0.2618 - val_mean_absolute_error: 0.2028\n",
      "Epoch 2/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2368 - mean_absolute_error: 0.1941 - val_loss: 0.2735 - val_mean_absolute_error: 0.2288\n",
      "Epoch 3/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2375 - mean_absolute_error: 0.1900 - val_loss: 0.2406 - val_mean_absolute_error: 0.1974\n",
      "Epoch 4/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2134 - mean_absolute_error: 0.1720 - val_loss: 0.2591 - val_mean_absolute_error: 0.2176\n",
      "Epoch 5/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1972 - mean_absolute_error: 0.1583 - val_loss: 0.2697 - val_mean_absolute_error: 0.2080\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(train_features_np, train_targets_np,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=5,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - 3ms/step - loss: 0.2472 - mean_absolute_error: 0.1949\n",
      "Test RMSE: 0.2471848428249359, Test MAE: 0.19494310021400452\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n del modelo\n",
    "test_loss, test_mae = model.evaluate(test_features_np, test_targets_np, verbose=2)\n",
    "print(f\"Test RMSE: {test_loss}, Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelos/Beto.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
