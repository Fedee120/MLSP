{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la oraci√≥n: tensor([[-1.0735e-01, -1.2773e-01,  4.5974e-02, -8.6625e-02, -2.2233e-01,\n",
      "          7.4742e-03, -1.1118e-01, -8.4462e-02, -1.8734e+00, -2.1577e-02,\n",
      "         -1.6335e-01, -1.5925e-01,  1.0128e-01,  6.2465e-02,  1.5979e-01,\n",
      "          9.9915e-02,  9.7223e-02, -3.8102e-02, -1.7053e-02,  2.0564e-02,\n",
      "         -9.6136e-02,  8.9360e-02, -5.5176e-02, -1.1231e-01,  5.0994e-01,\n",
      "         -6.1095e-02,  1.0382e-01, -8.3100e-02, -2.0854e+00, -5.8676e-02,\n",
      "         -2.8183e-01,  2.5542e-02, -3.5711e-02,  1.3042e-01,  4.4776e-02,\n",
      "         -6.0031e-02,  8.0662e-02,  1.6509e+00,  7.3684e-02,  7.6071e-02,\n",
      "         -8.1319e-02, -2.7686e-02, -7.7573e-02,  1.4531e-01, -4.5582e-02,\n",
      "         -6.0797e-02,  1.0566e-01, -2.4155e-02, -1.5657e-02, -3.4596e-02,\n",
      "         -6.2806e-02,  1.7225e-01,  2.8023e-02,  8.4980e-03, -1.2517e-01,\n",
      "          6.4119e-02, -9.5092e-02, -5.2815e-02,  6.9577e-04,  1.1222e-01,\n",
      "          1.8972e+00,  9.9849e-02, -1.2927e-01, -5.7768e-02,  6.6760e-02,\n",
      "          4.2508e-02, -7.4285e-02,  7.2298e-02, -1.1036e-02, -5.6757e-02,\n",
      "          1.6888e-02, -4.1419e-02, -5.5196e-02, -1.1518e-01, -6.1366e-02,\n",
      "         -1.7611e-01,  5.5366e-01,  2.3994e-02,  9.3573e-02,  3.5607e-02,\n",
      "          5.4522e-02, -2.6648e-02, -1.5872e-01, -3.8534e-03, -1.8508e-01,\n",
      "          2.4855e-02, -4.8727e-02,  1.4406e-02, -7.0611e-02, -1.2919e-01,\n",
      "          2.8431e-01, -1.0524e-01,  1.3611e-02,  2.9966e-02, -4.3829e-02,\n",
      "          1.1171e-01, -1.3646e-01,  1.9016e+00, -8.9845e-02,  1.4870e-01,\n",
      "          9.0735e-02, -1.5844e-03, -5.3396e-02, -4.1298e-02,  5.4458e-02,\n",
      "          3.1593e-02,  5.1041e-02,  1.4271e-01, -6.2444e-02, -1.9942e-03,\n",
      "          6.5249e-01, -1.9583e-01,  1.5592e-02, -6.9805e-02, -6.2001e-02,\n",
      "         -7.9707e-02,  2.9616e-02,  3.9974e-02, -7.7279e-02,  7.2751e-02,\n",
      "          6.1089e-02,  1.6580e+00, -4.2465e-02, -2.4356e-01, -1.7659e-01,\n",
      "          8.5824e-02, -1.2506e-01,  9.5462e-02,  7.9312e-03, -3.6765e-02,\n",
      "          1.2376e-01, -2.5908e-02,  1.0514e+00, -2.3018e-01,  1.9480e-01,\n",
      "          9.6608e-02, -1.5194e-01, -3.5988e-02,  1.3001e-01,  2.1196e-02,\n",
      "          6.5723e-02, -2.3173e-01,  2.6392e-02, -1.8922e-02, -9.7859e-03,\n",
      "         -8.0487e-02,  7.9933e-02, -1.0198e-02,  1.3761e-02,  4.5436e-02,\n",
      "         -2.2190e-02,  1.4347e-01, -3.9763e-02, -5.7175e-02, -1.6042e-02,\n",
      "          5.8917e-02, -6.9439e-04, -4.4669e-01, -1.4407e-02, -3.0657e+00,\n",
      "         -5.1135e-02, -1.0538e-02,  6.4978e-02,  3.0419e-02,  1.3101e+00,\n",
      "          3.6979e-02, -6.2184e-02,  7.3317e-02, -5.8032e-02, -5.1634e-02,\n",
      "         -3.5586e-02, -1.0177e-02,  3.7393e-03, -2.5746e-02, -2.4088e-01,\n",
      "          2.0918e-01, -5.3584e-02, -3.8051e-02, -6.5821e-02, -4.8825e-02,\n",
      "          2.5366e-02,  2.3652e-01, -1.6777e-01,  2.1002e-02, -8.3942e-02,\n",
      "          5.1112e-02, -2.0348e-01, -1.0402e-01, -6.9043e-02, -1.7971e-01,\n",
      "          1.1330e-01, -6.5755e-02, -3.4797e-02, -1.0301e-02, -1.0393e-01,\n",
      "         -8.1433e-02,  9.5716e-02, -2.9579e-02, -1.1655e-01,  1.6912e-03,\n",
      "         -2.1351e-02,  1.2689e-01, -2.3373e-02,  1.4412e-01,  1.5699e-03,\n",
      "         -6.6159e-02, -8.5998e-02, -1.1577e-02,  6.5054e-02,  1.9962e-02,\n",
      "          1.0290e-01, -4.2064e-02, -9.3873e-02, -4.6550e-02, -6.5130e-02,\n",
      "         -4.9529e-02, -7.8630e-02,  2.3155e-02,  1.4742e-02,  1.4562e-01,\n",
      "          3.1475e-02,  5.3838e-02,  3.4577e-02,  9.1479e-02, -1.1176e-01,\n",
      "          2.4068e-02, -9.1991e-02,  9.6703e-03, -1.0374e-01, -5.6698e-02,\n",
      "          1.0504e-01,  4.4126e-02, -1.4091e-01, -1.3352e-02,  7.8129e-02,\n",
      "         -1.6771e-01,  5.8787e-03,  2.5504e-02, -3.9451e-02, -3.8635e-02,\n",
      "         -4.5818e-03, -9.4482e-02,  7.0504e-02, -7.1996e-03,  1.5728e+00,\n",
      "          6.8778e-02, -1.9731e-02,  2.5545e-02,  8.8670e-02, -1.0000e-01,\n",
      "          4.7569e-02,  8.8253e-02, -1.6343e+00, -5.2266e-02, -6.8204e-02,\n",
      "          2.8491e-02,  1.9442e-01,  1.0051e-03, -4.1460e-02,  8.1402e-02,\n",
      "         -1.5822e+00, -1.0315e-01, -9.3847e-02, -6.2547e-02,  4.8660e-02,\n",
      "         -1.3574e-01,  8.2129e-02,  1.5536e-02, -3.4309e-02, -2.0433e-01,\n",
      "          2.5561e-02,  4.6136e-02,  1.6826e-02, -1.3612e-01,  4.6690e-02,\n",
      "         -1.0156e-01, -1.0440e-02,  1.2823e-01,  1.4052e-02, -4.3743e-02,\n",
      "         -1.3964e-01, -2.5139e-01,  2.1253e-02, -4.0752e-02, -4.3653e-02,\n",
      "          4.3598e-02,  4.2339e-02,  2.1372e-01,  4.1013e-02,  1.7652e-02,\n",
      "         -2.9719e+00, -4.7845e-04,  1.8256e-01, -4.5726e-02,  5.6169e-02,\n",
      "         -1.1010e-01, -8.5037e-02,  2.0370e-01,  5.4726e-02, -1.1751e-01,\n",
      "          2.3828e-02, -9.4899e-02,  5.0139e-03,  9.4253e-02, -1.1261e-01,\n",
      "         -8.2173e-02,  5.8620e-02,  1.1284e-01, -4.7124e-01, -1.2885e-02,\n",
      "         -1.5151e+00, -2.6161e-02, -1.9641e-01, -2.2742e-02, -9.0148e-02,\n",
      "         -1.0202e-01,  5.5866e-02,  3.6172e-02, -1.0827e-01, -5.1524e-02,\n",
      "          5.5153e-02,  1.9481e-02, -1.1772e-01, -5.0302e-03, -4.1474e-02,\n",
      "          7.0154e-02, -3.4176e-02,  8.2479e-02,  5.5978e-02, -1.4848e-01,\n",
      "          3.5646e-02,  1.7532e-01,  2.5843e-02, -5.4234e-02,  4.2433e-02,\n",
      "          7.6137e-03, -6.2118e-03, -2.1243e-02,  7.2486e-02,  1.3647e-01,\n",
      "         -4.8432e-02, -5.9155e-02,  1.6206e-02, -6.7379e-02,  1.2905e-01,\n",
      "         -2.8340e-01, -1.1929e-02, -1.5353e-01, -1.2478e-01,  9.2078e-03,\n",
      "         -8.5743e-02, -9.6165e-02, -1.2721e-01, -1.2044e-01,  2.1859e-02,\n",
      "         -1.0472e-01, -4.0326e-02,  3.3159e-02,  9.9793e-02,  3.8116e-02,\n",
      "         -5.7539e-03,  5.8945e-02, -4.5636e-02,  6.7524e-02, -2.7101e-02,\n",
      "         -2.2266e+00,  1.3616e-02,  1.1415e-01, -2.4484e-02, -4.5261e-02,\n",
      "          1.2502e-01,  2.8687e-02,  9.6098e-01,  9.5585e-02, -9.4494e-02,\n",
      "          3.4686e-03, -3.7329e-02,  1.8125e-01, -3.4617e-01, -4.8331e-02,\n",
      "         -2.5963e-02,  8.4177e-02, -9.1530e-02, -9.3996e-03, -4.5144e-03,\n",
      "         -4.4774e-02, -7.1327e-02,  5.2898e-02, -1.2248e-01,  7.2954e-03,\n",
      "          1.4743e-02,  3.0600e-02, -1.7367e-02, -2.8324e-01,  1.2329e-02,\n",
      "         -5.6518e-01,  9.3036e-02,  1.6644e-02, -1.4840e-01,  8.3335e-01,\n",
      "         -3.0342e-02, -7.1132e-02,  2.3564e-02,  1.5975e+00,  2.8810e-02,\n",
      "         -5.2045e-02,  1.5680e-01,  3.8145e-01,  3.4922e-02, -6.7639e-01,\n",
      "         -1.9477e+00,  1.3679e-02,  1.3010e-01, -2.8181e+00, -8.6948e-02,\n",
      "         -1.0359e-01,  1.1016e-02, -1.2208e-01, -3.5568e-01,  9.5770e-02,\n",
      "          8.6841e-02, -1.7526e+00,  2.3028e-02, -1.1561e-01,  1.2003e-01,\n",
      "         -7.1698e-02,  2.4324e-02,  1.4012e-01,  1.4299e+00,  1.3732e-01,\n",
      "          1.3916e-03, -3.9678e-02, -8.6692e-03, -6.3104e-02, -6.3596e-02,\n",
      "         -8.5743e-02,  2.7565e-01,  1.0532e-01, -9.3631e-03, -1.0493e-01,\n",
      "          1.1056e-01, -4.4695e-02, -6.4633e-02,  4.5760e-03, -7.2322e-02,\n",
      "          7.0131e-02,  2.3384e-03,  2.5285e+00,  2.1012e-03,  5.6710e-02,\n",
      "         -6.4498e-02, -2.2681e-03,  9.9093e-02,  1.5305e-01,  3.4344e-02,\n",
      "          2.9471e-02, -3.7995e-02,  1.4929e-01,  1.0509e-02,  1.9869e+00,\n",
      "         -4.5817e-02,  1.4682e-02,  6.5262e-03,  2.4571e-01, -6.9074e-02,\n",
      "          1.3814e-02, -1.2503e-01, -3.6606e-02,  1.6502e-01, -6.0218e-02,\n",
      "          1.8898e-01,  5.1783e-01, -1.2139e-01,  2.6052e-02, -7.1393e-03,\n",
      "          1.3503e-02,  8.1997e-03,  1.5181e-02, -2.1702e-01, -1.1997e-01,\n",
      "          5.5108e-02, -3.0221e-02,  5.3276e-02,  4.6117e-02, -7.6261e-02,\n",
      "         -4.0626e-02, -2.2612e-02,  6.9166e-02,  3.0922e-03,  9.9590e-02,\n",
      "         -8.5615e-02, -4.0470e-02,  7.3927e-02,  3.7603e-02, -1.2206e+00,\n",
      "         -1.0132e-01, -8.0179e-02, -5.7733e-02,  1.4917e-01,  1.5255e+00,\n",
      "          1.3342e-01, -2.4791e-02,  4.6902e-03,  5.4603e-03, -6.4219e-03,\n",
      "         -6.4461e-02,  1.6082e+00, -7.3420e-02, -1.5172e-01, -7.8833e-03,\n",
      "          1.0323e-01,  1.6121e-01, -6.1992e-02, -3.1745e-02,  1.3775e-02,\n",
      "          3.8947e-03,  4.4453e-02,  5.9884e-02,  3.0869e-02,  7.1772e-02,\n",
      "          7.1447e-02, -1.1341e-01,  1.0190e-01, -1.0056e-01,  1.3176e-01,\n",
      "         -6.4075e-03, -6.3481e-02,  8.4396e-03,  4.9616e-02,  1.5843e+00,\n",
      "         -4.4286e-02, -2.1135e-02,  1.4366e-01, -5.4475e-02, -1.9895e-01,\n",
      "         -7.4871e-03,  9.1998e-02, -6.5744e-02,  1.2336e-01,  1.9703e-02,\n",
      "         -9.1516e-02, -1.6209e-01, -4.2917e-02,  1.2818e+00,  7.7294e-03,\n",
      "          1.7440e-01, -4.0167e-01,  4.4009e-01,  5.2150e-02, -5.0616e-02,\n",
      "         -1.9010e-01, -1.7651e-01,  1.5223e-01, -3.1898e-02,  3.0355e-02,\n",
      "          5.3181e-01, -1.3163e-03,  6.5766e-02, -9.7406e-02, -1.4022e-01,\n",
      "         -3.0619e-03, -2.3741e-02, -6.6378e-02, -2.4192e+00, -1.5345e-01,\n",
      "          6.4190e-02, -3.3347e-02,  6.7954e-02,  3.9998e-02,  4.8744e-02,\n",
      "          8.6420e-02,  1.2192e-02, -1.2638e-01, -5.6311e-02,  8.1311e-02,\n",
      "          7.5113e-02, -5.8597e-02, -2.5198e-02, -1.9367e-01,  6.4913e-02,\n",
      "          5.7688e-03,  9.4919e-02,  4.3994e-02,  1.3431e-01,  1.5524e-01,\n",
      "          1.9231e-01, -1.9390e-02,  5.5767e-02,  9.9354e-02, -1.8451e-01,\n",
      "         -1.6286e-01,  2.2377e-02,  4.6561e-02, -1.1160e-01,  2.3469e-02,\n",
      "         -6.0582e-02,  2.2643e-02,  1.0874e-02,  6.8494e-02,  5.3939e-01,\n",
      "         -1.1041e+00,  3.3702e-02,  6.7455e-02,  1.2049e-01,  1.4462e+00,\n",
      "          5.7229e-02,  8.4045e-02, -1.3218e-01, -2.1138e-01,  7.8585e-02,\n",
      "         -8.5201e-02,  6.2169e-02, -1.1570e-01,  7.6306e-02,  6.7308e-02,\n",
      "         -6.4250e-03,  4.8352e-02,  1.8341e-01, -2.0275e-02, -1.1909e-01,\n",
      "          5.2366e-02, -4.7247e-02,  7.2048e-02,  1.1196e-02,  1.6683e-01,\n",
      "          1.0139e-01, -1.1834e-01,  1.2976e-01, -3.5342e-02, -3.4677e-02,\n",
      "         -1.7712e+00, -7.6835e-02,  2.2785e-03,  6.4695e-02,  1.1428e-02,\n",
      "         -1.4157e-01,  1.1047e+00,  7.0415e-02,  4.0998e-02, -2.2202e-03,\n",
      "          2.3518e-01,  1.8770e+00,  2.3538e-03, -4.1054e-02,  4.0920e-02,\n",
      "         -3.7895e-01,  8.6730e-02,  9.6530e-02,  1.9839e-02,  3.1334e-02,\n",
      "         -2.0428e+00,  4.6983e-02,  7.3365e-02,  5.5989e-02, -1.7116e+00,\n",
      "         -2.3394e-02, -5.8828e-02, -7.2517e-02,  5.7349e-02,  4.4577e-02,\n",
      "         -1.0471e-01,  2.2003e-01, -2.9165e-01, -1.0595e-01, -2.8665e-02,\n",
      "          3.1576e-02, -5.3289e-03, -1.6312e-01,  1.3904e+00, -2.1641e+00,\n",
      "         -7.6998e-02, -1.5983e-01,  5.8354e-02,  6.1271e-03,  6.1743e-02,\n",
      "          2.1390e-01,  1.7788e+00,  7.9476e-02,  1.7743e-02, -3.1025e-02,\n",
      "         -2.8501e-02,  9.3301e-02,  1.3111e-03, -6.8634e-02,  3.3390e-02,\n",
      "          7.8106e-02,  2.5951e-02, -1.2127e-01,  1.8924e-02,  2.4440e-01,\n",
      "         -7.2714e-03, -9.6309e-02, -6.5083e-02, -1.8015e+00,  2.1970e-02,\n",
      "         -3.2317e-02, -7.3041e-02, -1.5404e-01,  2.0077e+00, -9.7411e-03,\n",
      "          1.7158e-01,  1.5509e-02,  8.0833e-02, -5.0854e-03, -1.8527e-03,\n",
      "         -1.1203e-02, -8.1325e-03,  7.7903e-02, -4.7946e-02, -6.8523e-01,\n",
      "          8.7527e-02, -1.5215e-02,  4.3807e-02, -1.2195e-02,  1.4096e-02,\n",
      "         -7.5674e-02, -1.8002e-01,  5.2271e-02,  1.2230e-01,  3.0111e-02,\n",
      "         -9.6082e-02, -1.2347e-01, -1.5861e-02,  3.5263e-02, -6.6227e-02,\n",
      "         -1.8758e-02,  3.5594e-02,  1.5164e-01, -1.5697e+00,  3.4689e-02,\n",
      "          1.0300e-01,  1.6680e+00,  9.7139e-02, -1.9459e-01,  1.4263e+00,\n",
      "         -9.0580e-03,  4.7454e-02, -1.7737e-02, -4.1829e-02, -1.6371e-02,\n",
      "          7.7097e-02, -6.1320e-02, -1.8244e+00, -2.2345e+00, -7.4404e-02,\n",
      "          1.4708e-01,  7.3968e-02, -2.1173e-03, -3.4591e-02,  1.0754e-04,\n",
      "          2.7347e-02, -1.4803e-01,  6.5935e-02,  4.1325e-02, -2.5745e-02,\n",
      "          5.3734e-02, -6.2616e-03,  1.1798e+00,  1.1310e-02,  2.0814e+00,\n",
      "         -1.1363e-01, -1.1567e-01,  7.0790e-02, -5.6679e-02, -1.1448e-01,\n",
      "         -3.1191e-02, -8.1263e-02, -2.3865e-02]])\n",
      "Embeddings de las palabras: tensor([[[-0.1074, -0.1277,  0.0460,  ..., -0.0312, -0.0813, -0.0239],\n",
      "         [-0.2772, -0.4798,  0.0486,  ..., -0.5929,  0.3513, -0.6527],\n",
      "         [-0.5005, -0.1657,  0.0758,  ...,  0.1027, -0.2255, -1.2946],\n",
      "         ...,\n",
      "         [-0.1197, -0.1576,  0.2487,  ..., -0.2225,  0.0048, -0.2003],\n",
      "         [-0.0898,  0.2121, -0.1638,  ..., -0.2904, -0.4519, -0.1142],\n",
      "         [-0.0638, -0.0297,  0.2161,  ...,  0.3376,  0.2042, -0.8556]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Carga el tokenizador y el modelo\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "#model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n",
    "model = BertModel.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n",
    "\n",
    "# Oraci√≥n de ejemplo\n",
    "sentence = \"Hola, esto es una prueba con BERT.\"\n",
    "\n",
    "# Tokeniza la oraci√≥n\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Obtiene los embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Los embeddings de la √∫ltima capa oculta ser√≠an\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Embedding del [CLS] token que representa la oraci√≥n entera\n",
    "sentence_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "# Embeddings de cada token/palabra en la oraci√≥n\n",
    "word_embeddings = last_hidden_states\n",
    "\n",
    "print(\"Embedding de la oraci√≥n:\", sentence_embedding)\n",
    "print(\"Embeddings de las palabras:\", word_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "# Supongamos que tus datos est√°n en un archivo JSON llamado 'converted_data.jsonl'\n",
    "with open('../scripts/converted_data.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convertir los datos en un DataFrame de pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behold, there came up out of the river seven c...</td>\n",
       "      <td>river</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a fellow bondservant with you and with yo...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The man, the lord of the land, said to us, 'By...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shimei had sixteen sons and six daughters; but...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"He has put my brothers far from me.</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target_word  complexity\n",
       "0  Behold, there came up out of the river seven c...       river    0.000000\n",
       "1  I am a fellow bondservant with you and with yo...    brothers    0.000000\n",
       "2  The man, the lord of the land, said to us, 'By...    brothers    0.050000\n",
       "3  Shimei had sixteen sons and six daughters; but...    brothers    0.150000\n",
       "4               \"He has put my brothers far from me.    brothers    0.263889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.rename(columns={'sentence': 'sentence', 'token': 'target_word', 'complexity': 'complexity'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c0fa54d870446da79ea74db23c84e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479c7bad778c4965af6c521e91f16650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a3587c36824d72be906174a445fcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62bd2c19d7a455c9aa6c319910ae8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que df es tu DataFrame que incluye las columnas 'sentence', 'target_word' y 'complexity'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embeddings(text_list, tokenizer, model, device):\n",
    "    \"\"\"Obtiene embeddings [CLS] para una lista de textos, con barra de progreso.\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=\"Processing\", leave=True):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu())\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "\n",
    "def process_dataframe(df, tokenizer, model, device):\n",
    "    \"\"\"Procesa un dataframe para obtener embeddings y complejidades.\"\"\"\n",
    "    sentence_embeddings = get_embeddings(df['sentence'].tolist(), tokenizer, model, device)\n",
    "    word_embeddings = get_embeddings(df['target_word'].tolist(), tokenizer, model, device)\n",
    "    complexities = torch.tensor(df['complexity'].values, dtype=torch.float).unsqueeze(1)\n",
    "    return torch.cat((sentence_embeddings, word_embeddings, complexities), dim=1)\n",
    "\n",
    "# Procesar los conjuntos de entrenamiento y prueba\n",
    "train_data = process_dataframe(train_df, tokenizer, model, device)\n",
    "test_data = process_dataframe(test_df, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6129, 1537]), torch.Size([1533, 1537]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de entrenamiento (todas las columnas excepto la √∫ltima)\n",
    "train_features = train_data[:, :-1]\n",
    "# Objetivos de entrenamiento (√∫ltima columna)\n",
    "train_targets = train_data[:, -1]\n",
    "\n",
    "# Entradas de prueba\n",
    "test_features = test_data[:, :-1]\n",
    "# Objetivos de prueba\n",
    "test_targets = test_data[:, -1]\n",
    "\n",
    "# Aseg√∫rate de que los tensores est√©n en la CPU para convertirlos a arrays de NumPy\n",
    "train_features_np = train_features.numpy()\n",
    "train_targets_np = train_targets.numpy()\n",
    "test_features_np = test_features.numpy()\n",
    "test_targets_np = test_targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 256)               393472    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426497 (1.63 MB)\n",
      "Trainable params: 426497 (1.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=rmse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.1697 - mean_absolute_error: 0.1423 - val_loss: 0.1105 - val_mean_absolute_error: 0.0870\n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1111 - mean_absolute_error: 0.0866 - val_loss: 0.1125 - val_mean_absolute_error: 0.0868\n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.1084 - mean_absolute_error: 0.0847 - val_loss: 0.1296 - val_mean_absolute_error: 0.1061\n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1061 - mean_absolute_error: 0.0831 - val_loss: 0.1031 - val_mean_absolute_error: 0.0789\n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1057 - mean_absolute_error: 0.0823 - val_loss: 0.1030 - val_mean_absolute_error: 0.0805\n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1018 - mean_absolute_error: 0.0795 - val_loss: 0.1009 - val_mean_absolute_error: 0.0780\n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1016 - mean_absolute_error: 0.0795 - val_loss: 0.1079 - val_mean_absolute_error: 0.0823\n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.0987 - mean_absolute_error: 0.0770 - val_loss: 0.0999 - val_mean_absolute_error: 0.0778\n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.0995 - mean_absolute_error: 0.0782 - val_loss: 0.1071 - val_mean_absolute_error: 0.0811\n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.0989 - mean_absolute_error: 0.0771 - val_loss: 0.1110 - val_mean_absolute_error: 0.0845\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(train_features_np, train_targets_np,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 - 0s - loss: 0.1110 - mean_absolute_error: 0.0851 - 77ms/epoch - 2ms/step\n",
      "Test RMSE: 0.11103618890047073, Test MAE: 0.08508406579494476\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n del modelo\n",
    "test_loss, test_mae = model.evaluate(test_features_np, test_targets_np, verbose=2)\n",
    "print(f\"Test RMSE: {test_loss}, Test MAE: {test_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
