{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la oraci√≥n: tensor([[-8.6743e-02,  9.0471e-02,  1.3302e-02, -1.0595e-01,  3.9593e-02,\n",
      "         -1.7688e-02, -4.2758e-02, -2.3704e-03,  3.3589e-02, -1.0090e-01,\n",
      "         -4.4411e-02, -1.7645e-02,  7.2555e-02, -4.6160e-02,  7.3803e-02,\n",
      "          2.9888e-02, -5.5485e-02, -2.1723e-02, -2.7182e-02, -3.6914e-02,\n",
      "         -1.0021e-01,  1.2966e-02, -9.6302e-03,  9.4810e-02, -2.5938e-02,\n",
      "          8.1167e-02,  8.1004e-02,  8.1191e-02, -6.7600e-02,  5.5690e-02,\n",
      "         -5.8468e-02, -7.9548e-02,  5.6678e-02,  1.0321e-02,  6.8747e-02,\n",
      "          1.3197e-01,  4.0268e-02, -2.0073e-02, -4.9358e-02,  9.8386e-03,\n",
      "         -7.8971e-03,  1.7162e-01, -1.2055e-02,  1.9111e-02,  6.3142e-02,\n",
      "         -3.0365e-03,  2.0137e-02, -6.0194e-03, -3.0871e-02,  2.8043e-02,\n",
      "          4.6304e-02,  6.4634e-02, -3.9413e-02,  3.3905e-02, -1.8681e-01,\n",
      "          4.6870e-02,  5.5762e-02,  7.0085e-02, -3.2284e-02, -8.9200e-02,\n",
      "         -3.3546e-02, -1.7492e-01, -9.4362e-02, -8.4185e-02,  7.9824e-02,\n",
      "         -6.4356e-02, -2.3966e-02, -2.3705e-03,  5.4052e-02,  4.2706e-02,\n",
      "          5.3083e-02, -7.1791e-02,  4.2474e-02, -6.8317e-02, -2.1265e-02,\n",
      "          1.7003e-03, -8.7144e-04,  5.8259e-01, -1.0546e-01, -2.6488e-03,\n",
      "          4.7962e-02, -8.8415e-02,  5.7433e-01,  3.7707e-02, -1.6393e-02,\n",
      "          2.2908e-02,  1.3285e-01,  2.0244e-02,  7.2175e-02,  1.5951e-02,\n",
      "         -5.1774e-03,  1.1182e-01, -2.1540e-02,  5.1325e-02,  6.6964e-02,\n",
      "          1.7041e-02, -1.0916e-02,  1.0652e-01, -6.6942e-02, -4.0852e-02,\n",
      "         -1.5964e-02, -3.3983e-02,  4.7101e-02,  5.3062e-02, -9.5862e-03,\n",
      "          9.7275e-03,  4.1852e-02, -5.5519e-02,  9.6810e-03, -7.3549e-02,\n",
      "         -1.0728e-02, -2.0072e-02,  1.3953e-02,  3.2299e-03,  1.9211e-02,\n",
      "         -8.4088e-03,  1.2214e-02,  3.7154e-02,  6.7844e-03,  3.7385e-02,\n",
      "          2.1775e-03,  1.3629e-01,  1.0260e-01, -9.1276e-02, -7.9824e-02,\n",
      "         -1.0284e-01, -4.9118e-02, -2.4890e-02,  2.6205e-02,  5.0407e-02,\n",
      "          1.2743e-02, -1.8179e-01,  9.2737e-03,  7.1937e-02,  2.0900e-02,\n",
      "          2.4236e-02,  6.4589e-02, -1.1895e-02,  2.2920e-02, -3.1835e-02,\n",
      "         -4.1262e-02,  7.0507e-02,  6.6173e-02,  5.8911e-02,  1.4351e-01,\n",
      "          1.0444e-01,  4.9884e-03, -8.7025e-02,  1.5014e-02, -1.4191e-02,\n",
      "          6.8622e-02, -6.6471e-02, -7.0429e-02,  7.2723e-03, -8.5029e-02,\n",
      "          4.8415e-01,  1.4333e-01,  1.2038e-01, -1.5992e-02, -2.5905e-02,\n",
      "          2.0410e-01,  1.6836e-02,  4.8408e-02, -5.0916e-02, -1.2027e-02,\n",
      "          1.8297e-02, -3.6015e-02, -4.5086e-02,  8.1114e-02,  6.3954e-03,\n",
      "          4.7197e-02,  3.7210e-02,  3.9942e-02, -2.4866e-02, -5.6492e-02,\n",
      "         -1.1750e-01,  7.4873e-02, -2.9555e-02, -4.8449e-02,  1.1334e-02,\n",
      "         -7.6471e-03,  6.8405e-02, -5.8331e-02, -1.4195e-04, -6.2722e-02,\n",
      "          3.8658e-02,  4.7389e-02,  8.7322e-03, -1.6752e-02,  5.8300e-02,\n",
      "          1.8411e-02,  9.6821e-03,  1.0701e-02,  7.1668e-03, -4.4909e-02,\n",
      "          1.5090e-01, -6.0346e-02, -9.8261e-02,  3.3121e-02, -9.0658e-02,\n",
      "          5.0987e-02, -1.0283e-02,  1.1567e-01, -7.7358e-02,  7.9104e-02,\n",
      "         -5.7630e-02,  1.4953e-03,  5.0021e-02,  3.3252e-02, -1.0287e-01,\n",
      "         -3.4301e-02,  9.8115e-02, -2.2453e-03,  1.1546e-01,  6.7875e-02,\n",
      "         -2.4123e-02,  4.9959e-02,  1.0019e-01,  4.4557e-02, -1.0391e-02,\n",
      "          6.3904e-02,  4.6639e-02,  1.8554e-02,  5.8790e-02,  1.5598e-02,\n",
      "          4.7695e-04,  3.9351e-02,  1.7820e-02,  3.4559e-02,  1.6993e-03,\n",
      "         -5.6440e-02,  6.1581e-02, -2.0883e-02,  1.9933e-02,  4.1554e-02,\n",
      "         -1.3436e-01, -6.7343e-02, -2.7223e-03, -5.5864e-02,  2.1717e-02,\n",
      "         -6.8222e-02,  8.5155e-02,  7.7371e-02,  4.5317e-02, -2.3328e-02,\n",
      "          9.4403e-02,  1.8099e-02,  1.3443e-01, -3.5622e-02,  5.6076e-03,\n",
      "         -3.2309e-02, -7.1218e-02,  1.3196e-02, -1.5551e-02,  7.6710e-02,\n",
      "         -5.3467e-02, -7.7599e-02, -2.5763e-02, -5.2336e-02, -7.7012e-02,\n",
      "         -5.6431e-02, -1.8184e-02, -3.5745e-02, -2.6823e-02, -8.3008e-02,\n",
      "         -8.2588e-03, -5.7734e-02, -1.2789e-02,  2.3955e-02, -5.7827e-02,\n",
      "         -4.3641e-02, -7.6102e-02,  2.8734e-02, -5.5532e-02,  6.5056e-02,\n",
      "         -1.8184e-02,  3.2177e-02,  3.3695e-02, -6.3900e-02,  3.2411e-03,\n",
      "          1.3327e-02, -8.0932e-02, -7.2062e-02, -2.2342e-02,  4.3556e-02,\n",
      "          2.7921e-02, -1.1189e-01, -2.2369e-03,  2.1895e-02,  3.3051e-02,\n",
      "          7.1640e-02,  6.4862e-02, -4.5362e-02,  7.1812e-03,  6.7567e-03,\n",
      "          2.8241e-02,  1.1763e-01,  2.3648e-03,  2.0152e-02,  4.5825e-02,\n",
      "         -7.6199e-02, -6.2303e-02, -7.4943e-02, -6.0150e-04, -1.3798e-02,\n",
      "         -4.5531e-02, -4.1853e-03, -1.4137e-02,  8.3297e-03, -3.6659e-02,\n",
      "         -8.4431e-02, -4.6193e-02, -1.1460e-01,  1.2373e-01,  3.3450e-02,\n",
      "          5.2874e-02,  1.1699e-01, -4.8592e-02,  3.2757e-03,  9.1487e-03,\n",
      "         -1.5595e-02,  1.6432e-02,  8.7169e-02, -3.0965e-02,  1.7055e-02,\n",
      "          3.7752e-02, -1.2711e-02, -4.4712e-03,  3.1508e-02,  3.7556e-01,\n",
      "         -4.3821e-01,  6.0415e-02,  5.3841e-02, -1.6204e-02,  6.8832e-02,\n",
      "         -4.0509e-02,  2.5891e-02,  6.8478e-02,  1.2236e-01,  1.2096e-01,\n",
      "          2.7753e-03,  4.6244e-02, -6.1174e-02,  2.0870e-02,  4.1483e-02,\n",
      "          3.9333e-02,  3.4249e-02, -7.2197e-02,  1.1797e-02,  4.6559e-02,\n",
      "         -4.9932e-02, -3.5493e-02, -5.2618e-03, -1.2755e-01,  1.0938e-02,\n",
      "          7.1237e-02,  2.6775e-02, -1.6675e-02,  5.3055e-02, -1.7099e-02,\n",
      "          5.7736e-02, -3.6445e-02,  1.0127e-02, -6.9665e-02,  2.2873e-02,\n",
      "         -1.4900e-02, -3.9407e-02,  8.7542e-02,  7.8054e-03,  1.6078e-02,\n",
      "          7.2788e-02, -1.0226e-01, -1.8198e-02,  5.3635e-02, -5.4738e-02,\n",
      "          5.3820e-02,  6.6781e-02,  5.3486e-03,  2.6720e-02,  1.3598e-01,\n",
      "         -3.6011e-02,  2.6903e-02, -6.1963e-02,  3.8163e-02,  1.2751e-01,\n",
      "         -5.6785e-02,  2.9698e-02,  3.3416e-03,  1.1842e-02,  5.0823e-02,\n",
      "         -7.7384e-03, -3.6000e-02, -7.7595e-02, -7.9368e-02,  9.3840e-02,\n",
      "          2.2566e-02, -2.7545e-02, -1.2230e-01,  3.7427e-02, -2.3556e-02,\n",
      "          3.7161e-03,  5.8824e-02, -1.1056e-01,  2.3238e-02, -3.5951e-02,\n",
      "          4.7256e-02, -5.9929e-03, -4.3081e-02,  4.8444e-03, -8.8143e-02,\n",
      "         -3.2573e-03,  5.6883e-02,  7.1935e-02, -7.3077e-02, -1.0337e-02,\n",
      "         -6.1761e-02,  2.0064e-02, -1.3042e-02,  2.8062e-02, -3.7818e-02,\n",
      "         -9.2844e-02,  7.6943e-02,  1.5382e-02, -3.6681e-03, -6.0810e-02,\n",
      "          1.7291e-02, -5.2622e-03, -9.6783e-02, -7.4436e-02, -3.8297e-02,\n",
      "         -8.4023e-02,  7.7395e-02, -6.6495e-02, -5.2418e-02, -4.0357e-02,\n",
      "         -1.2484e-02, -9.0853e-03,  8.8094e-03, -3.9228e-02, -6.3117e-02,\n",
      "         -1.3712e-02, -3.8378e-02,  6.9894e-02, -4.1108e-02,  3.5698e-02,\n",
      "         -1.1856e-02,  5.6761e-02,  3.1018e-02, -5.1896e-02,  2.6637e-02,\n",
      "          4.4505e-02, -2.5184e-02, -3.4316e-02, -3.9187e-01,  1.6507e-02,\n",
      "         -2.3843e-02, -1.4641e-02,  3.4708e-02, -1.1836e-01, -2.1476e-02,\n",
      "          3.0096e-02,  1.9386e-02,  5.1916e-02, -5.2630e-02,  5.3614e-02,\n",
      "          1.2982e-02, -1.2577e-01,  2.6440e-02, -3.0028e-02, -6.7605e-02,\n",
      "          5.3799e-02, -3.2834e-02, -3.5097e-03, -9.1976e-02,  2.5720e-02,\n",
      "         -7.5433e-03,  7.5056e-02,  1.6252e-02, -2.5973e-02, -3.4907e-02,\n",
      "         -1.0997e-01,  2.5547e-02,  4.9485e-02,  3.0355e-02, -8.8491e-02,\n",
      "         -3.8394e-02, -1.3596e-02,  1.0127e-01,  9.7609e-02, -1.1586e-02,\n",
      "         -3.1623e-02, -1.4896e-02,  7.4673e-02,  5.8792e-02,  2.0987e-01,\n",
      "         -2.3352e-02,  1.8499e-01,  8.0364e-03,  1.4472e-01,  2.0066e-02,\n",
      "         -2.0418e-02, -6.2267e-02, -2.8395e-02,  2.9958e-02, -2.7348e-02,\n",
      "          1.8605e-02, -6.1872e-02, -4.7208e-02, -4.7697e-04,  3.5045e-02,\n",
      "         -2.0043e-03, -1.2379e-02,  1.2889e-01, -5.6674e-03,  5.7976e-02,\n",
      "         -2.3725e-03, -3.2176e-02,  2.2824e-03, -5.0932e-02, -1.4484e-02,\n",
      "         -2.8643e-02, -1.0998e-02, -6.7145e-03, -2.8820e-02, -5.0850e-02,\n",
      "          3.0008e-02,  9.0869e-04, -2.8689e-03,  1.2912e-01, -2.1780e-02,\n",
      "          7.1706e-02, -1.6418e-02,  9.0337e-02,  3.6220e-02,  4.2136e-02,\n",
      "          6.9658e-02,  8.3700e-02,  3.0262e-02, -4.8790e-02, -1.1796e-02,\n",
      "         -4.3879e-02,  1.5296e-02,  1.2515e-01, -1.4693e-02,  6.3432e-02,\n",
      "          4.6070e-02,  1.8349e-03, -6.7392e-02,  4.7925e-02, -6.1569e-03,\n",
      "          4.6544e-02, -6.3297e-01, -1.7998e-02,  6.0229e-02, -6.1232e-02,\n",
      "          3.7940e-02,  8.0922e-02,  1.0205e-01, -6.9558e-02, -7.6348e-02,\n",
      "         -4.6738e-02,  3.9310e-02,  2.6103e-02,  1.1121e-01, -5.0523e-02,\n",
      "          8.3239e-03,  6.4006e-02, -2.5629e-02, -1.9748e-03,  2.3842e-02,\n",
      "         -1.8833e-01, -3.5848e-02, -9.9692e-02,  6.4010e-02,  6.0714e-03,\n",
      "          2.6989e-02,  9.6472e-02, -4.8633e-02,  3.0026e-02,  4.0709e-02,\n",
      "          3.3020e-02,  4.7209e-02,  7.9793e-02, -2.1064e-02,  6.7029e-02,\n",
      "          3.6862e-02,  2.1208e-02,  3.3444e-02,  1.1688e+01, -3.3950e-02,\n",
      "          6.2024e-02, -2.2192e-02,  8.9378e-02, -9.0813e-02,  3.3272e-02,\n",
      "         -1.3194e-01, -2.4420e-02,  1.0027e-01,  1.8953e-03, -5.5741e-02,\n",
      "         -6.6146e-02, -7.9206e-02,  5.1552e-02,  6.5808e-03, -5.3897e-02,\n",
      "         -3.3205e-02,  5.1019e-02, -7.2768e-02, -2.9524e-02,  3.1030e-02,\n",
      "          4.5191e-02,  7.8182e-03, -7.7772e-02, -2.4332e-02,  9.7515e-02,\n",
      "         -4.3550e-02, -3.2143e-03,  1.1714e-02, -1.3523e-02,  1.0736e-02,\n",
      "          2.9821e-02,  5.3837e-03,  1.3487e-01,  9.5325e-03,  1.6973e-02,\n",
      "          5.9457e-02,  6.8512e-03,  3.9401e-02,  2.0757e-02, -1.4802e-02,\n",
      "          5.3943e-02,  3.3357e-03,  8.2559e-02,  5.0526e-02, -1.5916e-02,\n",
      "          1.0252e-01,  1.7452e-02,  3.0724e-02,  1.1270e-01, -5.8599e-02,\n",
      "          1.1657e-01,  2.8743e-03, -1.9818e-02,  3.5658e-02,  1.9350e-02,\n",
      "          2.2838e-03,  5.1655e-02,  4.5689e-02, -8.0219e-02,  7.6608e-02,\n",
      "         -1.0359e-02,  9.4137e-03,  1.6960e-02,  1.5585e-01,  1.2570e-01,\n",
      "          1.0169e-01, -9.1311e-02, -5.2549e-02,  1.8293e-02, -4.6609e-02,\n",
      "         -9.7340e-02,  9.2755e-03,  9.1867e-02, -3.9546e-02, -5.0251e-02,\n",
      "          2.5232e-02, -5.0176e-02, -4.5388e-02,  7.4674e-04,  1.1431e-02,\n",
      "          7.0852e-02, -1.1171e-02,  1.4328e-01,  7.2943e-02,  4.3729e-02,\n",
      "          4.7126e-02, -2.1214e-02, -3.7605e-02, -1.0752e-02,  1.4330e-02,\n",
      "         -9.5570e-04, -7.0456e-02, -1.7287e-02, -6.2811e-02,  2.4195e-02,\n",
      "         -1.3933e-01,  2.6549e-03,  6.0007e-02, -1.0736e-01,  3.3857e-02,\n",
      "         -8.7800e-03,  5.2284e-02,  4.4929e-02,  4.3290e-02, -9.9814e-02,\n",
      "         -3.0825e-02,  1.8337e-02, -9.4106e-03, -3.1660e-02,  6.6286e-03,\n",
      "          8.0725e-02, -5.7424e-02,  3.3407e-04,  5.2773e-02,  4.2248e-02,\n",
      "         -1.3652e-02,  5.9522e-02,  1.0129e-01, -1.0252e-01, -3.1620e-02,\n",
      "         -3.0927e-02, -5.7649e-02, -3.2964e-02, -4.4436e-02,  1.1286e-02,\n",
      "          1.1290e-02, -9.7263e-03,  3.5122e-02,  1.9145e-02,  3.9285e-02,\n",
      "          2.4979e-02, -5.6798e-02,  7.2913e-02, -6.7388e-02, -7.7330e-02,\n",
      "          6.2795e-02,  6.4434e-02,  7.3127e-02,  3.7289e-02, -2.3990e-02,\n",
      "         -1.1057e-01, -8.7222e-02,  4.9239e-02,  6.7422e-02,  5.2799e-02,\n",
      "          7.7512e-02,  7.4028e-02, -1.2066e-01,  1.2572e-02,  1.5012e-02,\n",
      "          5.2393e-02,  1.4407e-02,  7.1811e-03, -2.4598e-02, -2.7794e-02,\n",
      "          8.4707e-02, -3.1796e-02,  1.6741e-02,  6.1139e-02,  3.0692e-02,\n",
      "          8.7058e-02,  5.8987e-02, -7.9976e-03,  4.7452e-02, -1.7074e-02,\n",
      "          4.8237e-02,  2.7335e-03, -2.1023e-02, -7.5197e-04, -1.3585e-02,\n",
      "         -1.1437e-01, -1.0344e-01,  1.5145e-02,  1.4822e-01,  4.3539e-03,\n",
      "         -4.8190e-02, -1.9033e-02, -4.6459e-02]])\n",
      "Embeddings de las palabras: tensor([[[-0.0867,  0.0905,  0.0133,  ..., -0.0482, -0.0190, -0.0465],\n",
      "         [ 0.0652, -0.0678, -0.1393,  ...,  0.0322,  0.0991,  0.1104],\n",
      "         [-0.0032,  0.2392, -0.0245,  ..., -0.3839,  0.0199,  0.1572],\n",
      "         ...,\n",
      "         [-0.0129,  0.2340, -0.0339,  ...,  0.0248,  0.1979,  0.2229],\n",
      "         [-0.0739,  0.0814, -0.0025,  ..., -0.0717, -0.0166, -0.0734],\n",
      "         [-0.0039,  0.0613, -0.0262,  ...,  0.1493,  0.0737,  0.1269]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "# Carga el tokenizador y el modelo\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "#model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model_roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Oraci√≥n de ejemplo\n",
    "sentence = \"Hola, esto es una prueba con BERT.\"\n",
    "\n",
    "# Tokeniza la oraci√≥n\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Obtiene los embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model_roberta(**inputs)\n",
    "\n",
    "# Los embeddings de la √∫ltima capa oculta ser√≠an\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Embedding del [CLS] token que representa la oraci√≥n entera\n",
    "sentence_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "# Embeddings de cada token/palabra en la oraci√≥n\n",
    "word_embeddings = last_hidden_states\n",
    "\n",
    "print(\"Embedding de la oraci√≥n:\", sentence_embedding)\n",
    "print(\"Embeddings de las palabras:\", word_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import json\n",
    "# Supongamos que tus datos est√°n en un archivo JSON llamado 'converted_data.jsonl'\n",
    "with open('../scripts/converted_data.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convertir los datos en un DataFrame de pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behold, there came up out of the river seven c...</td>\n",
       "      <td>river</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a fellow bondservant with you and with yo...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The man, the lord of the land, said to us, 'By...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shimei had sixteen sons and six daughters; but...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"He has put my brothers far from me.</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target_word  complexity\n",
       "0  Behold, there came up out of the river seven c...       river    0.000000\n",
       "1  I am a fellow bondservant with you and with yo...    brothers    0.000000\n",
       "2  The man, the lord of the land, said to us, 'By...    brothers    0.050000\n",
       "3  Shimei had sixteen sons and six daughters; but...    brothers    0.150000\n",
       "4               \"He has put my brothers far from me.    brothers    0.263889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "df.rename(columns={'sentence': 'sentence', 'token': 'target_word', 'complexity': 'complexity'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_roberta.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6129/6129 [05:31<00:00, 18.50it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6129/6129 [03:06<00:00, 32.94it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1533/1533 [01:21<00:00, 18.85it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1533/1533 [00:44<00:00, 34.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que df es tu DataFrame que incluye las columnas 'sentence', 'target_word' y 'complexity'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_embeddings(text_list, tokenizer, model, device):\n",
    "    \"\"\"Obtiene embeddings [CLS] para una lista de textos, con barra de progreso.\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=\"Processing\", leave=True):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu())\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "\n",
    "def process_dataframe(df, tokenizer, model, device):\n",
    "    \"\"\"Procesa un dataframe para obtener embeddings y complejidades.\"\"\"\n",
    "    sentence_embeddings = get_embeddings(df['sentence'].tolist(), tokenizer, model, device)\n",
    "    word_embeddings = get_embeddings(df['target_word'].tolist(), tokenizer, model, device)\n",
    "    complexities = torch.tensor(df['complexity'].values, dtype=torch.float).unsqueeze(1)\n",
    "    return torch.cat((sentence_embeddings, word_embeddings, complexities), dim=1)\n",
    "\n",
    "# Procesar los conjuntos de entrenamiento y prueba\n",
    "train_data = process_dataframe(train_df, tokenizer, model_roberta, device)\n",
    "test_data = process_dataframe(test_df, tokenizer, model_roberta, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6129, 1537]), torch.Size([1533, 1537]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas de entrenamiento (todas las columnas excepto la √∫ltima)\n",
    "train_features = train_data[:, :-1]\n",
    "# Objetivos de entrenamiento (√∫ltima columna)\n",
    "train_targets = train_data[:, -1]\n",
    "\n",
    "# Entradas de prueba\n",
    "test_features = test_data[:, :-1]\n",
    "# Objetivos de prueba\n",
    "test_targets = test_data[:, -1]\n",
    "\n",
    "# Aseg√∫rate de que los tensores est√©n en la CPU para convertirlos a arrays de NumPy\n",
    "train_features_np = train_features.numpy()\n",
    "train_targets_np = train_targets.numpy()\n",
    "test_features_np = test_features.numpy()\n",
    "test_targets_np = test_targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 19:43:37.138109: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 19:43:37.138514: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 19:43:37.140949: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 19:43:37.165931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 19:43:37.808602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spoturno/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ       \u001b[38;5;34m393,472\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ        \u001b[38;5;34m32,896\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ           \u001b[38;5;34m129\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">426,497</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m426,497\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=rmse,\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1845 - mean_absolute_error: 0.1536 - val_loss: 0.1166 - val_mean_absolute_error: 0.0895\n",
      "Epoch 2/5\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1202 - mean_absolute_error: 0.0950 - val_loss: 0.1183 - val_mean_absolute_error: 0.0964\n",
      "Epoch 3/5\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1146 - mean_absolute_error: 0.0903 - val_loss: 0.1132 - val_mean_absolute_error: 0.0911\n",
      "Epoch 4/5\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1133 - mean_absolute_error: 0.0892 - val_loss: 0.1065 - val_mean_absolute_error: 0.0832\n",
      "Epoch 5/5\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - mean_absolute_error: 0.0832 - val_loss: 0.1084 - val_mean_absolute_error: 0.0838\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(train_features_np, train_targets_np,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=5,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 - 0s - 755us/step - loss: 0.1104 - mean_absolute_error: 0.0854\n",
      "Test RMSE: 0.11041993647813797, Test MAE: 0.08538506180047989\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n del modelo\n",
    "test_loss, test_mae = model.evaluate(test_features_np, test_targets_np, verbose=2)\n",
    "print(f\"Test RMSE: {test_loss}, Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelos/roberta.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_1</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>external</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_2</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>pulled</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_3</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>robot</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_4</td>\n",
       "      <td>english</td>\n",
       "      <td>A bank holiday was declared in October, 1857 a...</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_5</td>\n",
       "      <td>english</td>\n",
       "      <td>A bank holiday was declared in October, 1857 a...</td>\n",
       "      <td>recommended</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     en  english                                           sentence  \\\n",
       "0  en_1  english  (If your robot has an external ROM chip, then ...   \n",
       "1  en_2  english  (If your robot has an external ROM chip, then ...   \n",
       "2  en_3  english  (If your robot has an external ROM chip, then ...   \n",
       "3  en_4  english  A bank holiday was declared in October, 1857 a...   \n",
       "4  en_5  english  A bank holiday was declared in October, 1857 a...   \n",
       "\n",
       "   target_word  complexity  \n",
       "0     external       0.050  \n",
       "1       pulled       0.075  \n",
       "2        robot       0.100  \n",
       "3         bank       0.050  \n",
       "4  recommended       0.100  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file_path = '/home/spoturno/coding/MLSP_Data/Data/Trial/English/multilex_trial_en_lcp.tsv'\n",
    "output_file_path = input_file_path.replace('.tsv', '_results.csv')\n",
    "\n",
    "df = pd.read_csv(input_file_path, delimiter='\\t', header=None, names=['en', 'english', 'sentence', 'target_word', 'complexity'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:01<00:00, 21.00it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 31.99it/s]\n"
     ]
    }
   ],
   "source": [
    "trial_set = process_dataframe(df, tokenizer, model_roberta, device)\n",
    "trial_set = trial_set[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20652038],\n",
       "       [0.25688586],\n",
       "       [0.2572097 ],\n",
       "       [0.21194036],\n",
       "       [0.24448399],\n",
       "       [0.23518422],\n",
       "       [0.2664583 ],\n",
       "       [0.2275541 ],\n",
       "       [0.24204208],\n",
       "       [0.23635852],\n",
       "       [0.22951178],\n",
       "       [0.3072675 ],\n",
       "       [0.19964758],\n",
       "       [0.19693808],\n",
       "       [0.22286552],\n",
       "       [0.22455461],\n",
       "       [0.31093186],\n",
       "       [0.17485131],\n",
       "       [0.3565332 ],\n",
       "       [0.32344016],\n",
       "       [0.5171901 ],\n",
       "       [0.28175122],\n",
       "       [0.29498526],\n",
       "       [0.22343525],\n",
       "       [0.21585411],\n",
       "       [0.41237637],\n",
       "       [0.38575527],\n",
       "       [0.28936362],\n",
       "       [0.26961926],\n",
       "       [0.24201028]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(trial_set.numpy())\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['complexity'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>english</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_word</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_1</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>external</td>\n",
       "      <td>0.206520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_2</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>pulled</td>\n",
       "      <td>0.256886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_3</td>\n",
       "      <td>english</td>\n",
       "      <td>(If your robot has an external ROM chip, then ...</td>\n",
       "      <td>robot</td>\n",
       "      <td>0.257210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_4</td>\n",
       "      <td>english</td>\n",
       "      <td>A bank holiday was declared in October, 1857 a...</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.211940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_5</td>\n",
       "      <td>english</td>\n",
       "      <td>A bank holiday was declared in October, 1857 a...</td>\n",
       "      <td>recommended</td>\n",
       "      <td>0.244484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     en  english                                           sentence  \\\n",
       "0  en_1  english  (If your robot has an external ROM chip, then ...   \n",
       "1  en_2  english  (If your robot has an external ROM chip, then ...   \n",
       "2  en_3  english  (If your robot has an external ROM chip, then ...   \n",
       "3  en_4  english  A bank holiday was declared in October, 1857 a...   \n",
       "4  en_5  english  A bank holiday was declared in October, 1857 a...   \n",
       "\n",
       "   target_word  complexity  \n",
       "0     external    0.206520  \n",
       "1       pulled    0.256886  \n",
       "2        robot    0.257210  \n",
       "3         bank    0.211940  \n",
       "4  recommended    0.244484  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/spoturno/coding/MLSP/metrics/roberta_with_mlp/res/predictiones.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
